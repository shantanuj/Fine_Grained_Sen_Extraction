{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.InteractiveSession at 0x7f1dd8688850>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x1 = tf.eye(5,batch_shape=[3])\n",
    "x2 = tf.random_uniform([5,2,3])\n",
    "x = tf.convert_to_tensor(np.array([[[1,2,3,4],[10,11,12,13]],[[1,2,3,4],[10,11,12,13]],[[3,2,4,5],[8,13,2,1]]]), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.,  2.,  3.,  4.],\n",
       "        [10., 11., 12., 13.]],\n",
       "\n",
       "       [[ 1.,  2.,  3.,  4.],\n",
       "        [10., 11., 12., 13.]],\n",
       "\n",
       "       [[ 3.,  2.,  4.,  5.],\n",
       "        [ 8., 13.,  2.,  1.]]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x = tf.expand_dims(x,2)\n",
    "x.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "concat_within = lambda row: tf.concat([row,x[0,:]],1)\n",
    "#y = tf.concat([x[0,],x[0,:]],1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "els = tf.map_fn(concat_within, x, dtype=tf.float32)[1:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.,  2.,  3.,  4.,  1.,  2.,  3.,  4.],\n",
       "        [10., 11., 12., 13., 10., 11., 12., 13.]],\n",
       "\n",
       "       [[ 3.,  2.,  4.,  5.,  1.,  2.,  3.,  4.],\n",
       "        [ 8., 13.,  2.,  1., 10., 11., 12., 13.]]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "els.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "els = tf.reshape(els,[els.shape[0]*els.shape[1],els.shape[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.,  4.,  1.,  2.,  3.,  4.],\n",
       "       [10., 11., 12., 13., 10., 11., 12., 13.],\n",
       "       [ 3.,  2.,  4.,  5.,  1.,  2.,  3.,  4.],\n",
       "       [ 8., 13.,  2.,  1., 10., 11., 12., 13.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "els.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "encoder_embeds = 4\n",
    "condense_embeds = 2\n",
    "def condense(inp):\n",
    "    with tf.variable_scope(\"condense\"):\n",
    "        W = tf.get_variable(\"W\", dtype = tf.float32, shape=[2*encoder_embeds,condense_embeds])\n",
    "        b=  tf.get_variable(\"b\", dtype = tf.float32, shape=[condense_embeds], initializer= tf.zeros_initializer())\n",
    "        return tf.matmul(inp,W) + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "out = condense(els)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py:107: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -2.202735 ,   5.1193056],\n",
       "       [-13.070811 ,  19.441303 ],\n",
       "       [ -2.9686675,   6.2830596],\n",
       "       [ -3.753151 ,  14.768406 ]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.global_variables_initializer().run() # or \n",
    "tf.initialize_all_variables().run()\n",
    "out.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(4), Dimension(2)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = tf.reshape(out, [-1,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ -2.202735 ,   5.1193056],\n",
       "        [-13.070811 ,  19.441303 ]],\n",
       "\n",
       "       [[ -2.9686675,   6.2830596],\n",
       "        [ -3.753151 ,  14.768406 ]]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "xh = x[:,:,:2]\n",
    "xc = x[:,:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.,  2.],\n",
       "        [10., 11.]],\n",
       "\n",
       "       [[ 1.,  2.],\n",
       "        [10., 11.]],\n",
       "\n",
       "       [[ 3.,  2.],\n",
       "        [ 8., 13.]]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xh.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "normalized_xh = tf.nn.l2_normalize(xh, dim = 2)\n",
    "normalized_xc = tf.nn.l2_normalize(xc, dim = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mul_h = tf.multiply(normalized_xh, normalized_xh[0,:,])[1:]\n",
    "mul_c = tf.multiply(normalized_xc, normalized_xc[0,:,])[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.99999994],\n",
       "        [0.9999999 ]],\n",
       "\n",
       "       [[0.8682431 ],\n",
       "        [0.98272216]]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_similar_h = tf.reduce_sum(mul_h, 2, keep_dims=True)\n",
    "cos_similar_c = tf.reduce_sum(mul_c, 2, keep_dims=True)\n",
    "cos_similar_h.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cos_similar = tf.concat([cos_similar_h,cos_similar_c],axis =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.99999994, 1.        ],\n",
       "        [0.9999999 , 0.9999997 ]],\n",
       "\n",
       "       [[0.8682431 , 0.9995121 ],\n",
       "        [0.98272216, 0.93528605]]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_similar.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cos_similar_batch_major = tf.transpose(cos_similar, perm = [1,0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.9999999 ],\n",
       "        [0.94295406]],\n",
       "\n",
       "       [[0.9999999 ],\n",
       "        [0.83980083]]], dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_similar_batch_major."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(3), Dimension(2), Dimension(3)])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fn must be callable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-f703d5aeac4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_cos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/functional_ops.pyc\u001b[0m in \u001b[0;36mmap_fn\u001b[0;34m(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name)\u001b[0m\n\u001b[1;32m    298\u001b[0m   \"\"\"\n\u001b[1;32m    299\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fn must be callable.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fn must be callable."
     ]
    }
   ],
   "source": [
    "mul = lambda x: tf.multiply(x,tf.expand_dims(x1[0,:,],1))\n",
    "#y_cos = tf.map_fn(tf.map_fn(mul, x1),x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.9999999, 0.       , 0.       , 0.       , 0.       ],\n",
       "        [0.       , 0.9999999, 0.       , 0.       , 0.       ],\n",
       "        [0.       , 0.       , 0.9999999, 0.       , 0.       ],\n",
       "        [0.       , 0.       , 0.       , 0.9999999, 0.       ],\n",
       "        [0.       , 0.       , 0.       , 0.       , 0.9999999]],\n",
       "\n",
       "       [[0.9999999, 0.       , 0.       , 0.       , 0.       ],\n",
       "        [0.       , 0.9999999, 0.       , 0.       , 0.       ],\n",
       "        [0.       , 0.       , 0.9999999, 0.       , 0.       ],\n",
       "        [0.       , 0.       , 0.       , 0.9999999, 0.       ],\n",
       "        [0.       , 0.       , 0.       , 0.       , 0.9999999]],\n",
       "\n",
       "       [[0.9999999, 0.       , 0.       , 0.       , 0.       ],\n",
       "        [0.       , 0.9999999, 0.       , 0.       , 0.       ],\n",
       "        [0.       , 0.       , 1.       , 0.       , 0.       ],\n",
       "        [0.       , 0.       , 0.       , 1.       , 0.       ],\n",
       "        [0.       , 0.       , 0.       , 0.       , 1.       ]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cos.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.]],\n",
       "\n",
       "       [[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.]],\n",
       "\n",
       "       [[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.]]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Given a tensor like [[1,2,3,0,0,0],[3,4,5,6,0,0]]\n",
    "#convert to [[[1,2,3,0,0,0],[2,3,0,0,0],[1,3,0,0,0],[1,2,0,0,0],etc]]\n",
    "\n",
    "#We first output for lengths of n again (where n is max length)\n",
    "#Then we concat to original column\n",
    "\n",
    "\n",
    "#IN seq2seq processing, make sure to read in the seq_length.<- Very imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#We plan to apply a map_fn to each which does that\n",
    "#The map_fn creates a new batch by applying ignore given indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "shape_input_word_seq = tf.shape(input_word_seq_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "resultant_tensor = tf.expand_dims(input_word_seq_tensor,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "re = tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.InteractiveSession at 0x7f0f08477810>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#resultant_tensor.get_shape()\n",
    "tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string or a number, not 'Tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-7891f4ffd1dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_input_word_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dims)\u001b[0m\n\u001b[1;32m    450\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;31m# Treat as a singleton dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mas_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;31m# Got a list of dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.pyc\u001b[0m in \u001b[0;36mas_dimension\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m       if (not isinstance(value, compat.bytes_or_text_types) and\n\u001b[1;32m     34\u001b[0m           self._value != value):\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string or a number, not 'Tensor'"
     ]
    }
   ],
   "source": [
    "tf.TensorShape(shape_input_word_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(5), Dimension(5)])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.TensorShape([None,5,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'ones_13:0' shape=(2,) dtype=int32>,\n",
       " <tf.Tensor 'Const_60:0' shape=(2,) dtype=int32>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tf.ones(shape=(seq_lengths.shape[0],),dtype=\"int32\"), tf.convert_to_tensor(np.ones(shape=(seq_lengths.shape[0]),dtype=\"int32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0, 1, 2, 3, 1, 2],\n",
      "       [1, 2, 3, 4, 3, 2],\n",
      "       [1, 2, 3, 1, 2, 0],\n",
      "       [2, 3, 4, 3, 2, 0],\n",
      "       [0, 2, 3, 1, 2, 0],\n",
      "       [1, 3, 4, 3, 2, 0],\n",
      "       [0, 1, 3, 1, 2, 0],\n",
      "       [1, 2, 4, 3, 2, 0],\n",
      "       [0, 1, 2, 1, 2, 0],\n",
      "       [1, 2, 3, 3, 2, 0],\n",
      "       [0, 1, 2, 3, 2, 0],\n",
      "       [1, 2, 3, 4, 2, 0],\n",
      "       [0, 1, 2, 3, 1, 0],\n",
      "       [1, 2, 3, 4, 3, 0]], dtype=int32), array([4, 5, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4], dtype=int32), 6)\n",
      "0.900222063065\n"
     ]
    }
   ],
   "source": [
    "tf.InteractiveSession()\n",
    "\n",
    "input_word_seq_tensor = tf.convert_to_tensor(np.array([[0,1,2,3,1,2],[1,2,3,4,3,2]]),dtype='int32')\n",
    "max_seq_length = 6\n",
    "seq_lengths = tf.convert_to_tensor(np.array([4,5]),dtype='int32') #shape n\n",
    "'''Create mask based on max seq length'''\n",
    "\n",
    "t1 = time.time()\n",
    "np_mask_matrix = np.ones((max_seq_length,max_seq_length)) #num drops=n\n",
    "a = np.array(range(max_seq_length))\n",
    "np_mask_matrix[np.arange(len(a)), a] = 0\n",
    "#np_mask_matrix  = np_mask_matrix!=0\n",
    "tf_mask_matrix = tf.convert_to_tensor(np_mask_matrix, dtype=\"bool\")\n",
    "padding = tf.constant([[0,0],[0,1]],dtype='int32')\n",
    "resultant_tensor = tf.expand_dims(input_word_seq_tensor,0)\n",
    "#print(resultant_tensor.eval())\n",
    "tensor_seq_lengths = tf.expand_dims(seq_lengths, 0)\n",
    "seq_lengths_for_dropped = tf.expand_dims(seq_lengths-tf.ones(shape=(seq_lengths.shape[0],),dtype=\"int32\"),0)\n",
    "\n",
    "drop_index = tf.constant(0)\n",
    "max_sequence_length = tf.convert_to_tensor(max_seq_length, dtype=\"int32\")\n",
    "def condition(resultant_tensor, tensor_seq_lengths,drop_index):\n",
    "    return drop_index< max_seq_length\n",
    "\n",
    "def body(resultant_tensor, tensor_seq_lengths,drop_index):\n",
    "    f = lambda word_seq: tf.boolean_mask(word_seq, tf_mask_matrix[:,drop_index])#,padding,\"CONSTANT\") \n",
    "    '''Apply masking and padding'''\n",
    "    temp = tf.pad(tf.map_fn(f, input_word_seq_tensor), padding, \"CONSTANT\") #We apply mask and then pad result to enable concatenation with original \n",
    "    temp = tf.expand_dims(temp,0)\n",
    "    resultant_tensor = tf.concat([resultant_tensor,temp],0)\n",
    "    tensor_seq_lengths = tf.concat([tensor_seq_lengths, seq_lengths_for_dropped],0)\n",
    "    drop_index+=1\n",
    "    return resultant_tensor, tensor_seq_lengths, drop_index\n",
    "\n",
    "result = resultant_tensor, tensor_seq_lengths, drop_index = tf.while_loop(condition, \n",
    "                                                                 body, \n",
    "                                                                 [resultant_tensor, tensor_seq_lengths,0], \n",
    "                                                                 shape_invariants= [tf.TensorShape([None,input_word_seq_tensor.shape[0],max_seq_length]),tf.TensorShape([None,input_word_seq_tensor.shape[0],]),drop_index.get_shape()])\n",
    "\n",
    "\n",
    "resultant_tensor_shape = tf.shape(resultant_tensor)\n",
    "#tensor_seq_shape = tf.shape()\n",
    "resultant_tensor = tf.reshape(resultant_tensor,[resultant_tensor_shape[0]*resultant_tensor_shape[1],resultant_tensor_shape[2]])\n",
    "tensor_seq_lengths = tf.reshape(tensor_seq_lengths,[resultant_tensor_shape[0]*resultant_tensor_shape[1],])\n",
    "x= resultant_tensor.eval()\n",
    "\n",
    "print(resultant_tensor.eval(), tensor_seq_lengths.eval(), drop_index.eval())\n",
    "t2 = time.time()\n",
    "print(t2-t1)\n",
    "#resultant_tensor, tensor_seq_lengths, drop_index = ([resultant_tensor, tensor_seq_lengths, drop_index])\n",
    "#seq2seq_in = tf.reshape(resultant_tensor,[resultant_tensor.shape[0]*resultant_tensor.shape[1],resultant_tensor.shape[2]])\n",
    "#seq2seq_in_lengths = tf.reshape(tensor_seq_lengths,[tensor_seq_lengths.shape[0]*tensor_seq_lengths.shape[1],])\n",
    "\n",
    "#print(seq2seq_in.eval())\n",
    "#print(seq2seq_in.shape)\n",
    "#print(seq2seq_in_lengths.eval())\n",
    "#print(seq2seq_in_lengths.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 1, 2, 3, 1, 2],\n",
       "        [1, 2, 3, 4, 3, 2]],\n",
       "\n",
       "       [[1, 2, 3, 1, 2, 0],\n",
       "        [2, 3, 4, 3, 2, 0]],\n",
       "\n",
       "       [[0, 2, 3, 1, 2, 0],\n",
       "        [1, 3, 4, 3, 2, 0]],\n",
       "\n",
       "       [[0, 1, 3, 1, 2, 0],\n",
       "        [1, 2, 4, 3, 2, 0]],\n",
       "\n",
       "       [[0, 1, 2, 1, 2, 0],\n",
       "        [1, 2, 3, 3, 2, 0]],\n",
       "\n",
       "       [[0, 1, 2, 3, 2, 0],\n",
       "        [1, 2, 3, 4, 2, 0]],\n",
       "\n",
       "       [[0, 1, 2, 3, 1, 0],\n",
       "        [1, 2, 3, 4, 3, 0]]], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(\"../data/vocab_to_id.pkl\",'r') as p1:\n",
    "    x = pickle.load(p1)\n",
    "x_inv = {val:key for key,val in x.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'.' == 'empty .'[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'i.e'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-a9aa6efe43ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'i.e'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#x_inv[4327]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'i.e'"
     ]
    }
   ],
   "source": [
    "x['i.e']\n",
    "#x_inv[4327]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  1  2]\n",
      " [ 9 10 11 12 13 12]\n",
      " [ 1  2  3  1  2  0]\n",
      " [10 11 12 13 12  0]\n",
      " [ 0  2  3  1  2  0]\n",
      " [ 9 11 12 13 12  0]\n",
      " [ 0  1  3  1  2  0]\n",
      " [ 9 10 12 13 12  0]\n",
      " [ 0  1  2  1  2  0]\n",
      " [ 9 10 11 13 12  0]\n",
      " [ 0  1  2  3  2  0]\n",
      " [ 9 10 11 12 12  0]\n",
      " [ 0  1  2  3  1  0]\n",
      " [ 9 10 11 12 13  0]]\n",
      "[4 5 3 4 3 4 3 4 3 4 3 4 3 4]\n",
      "[[0.37692606 0.0892903  0.05837255 0.93667809 0.5931503  0.01183983\n",
      "  0.87316713 0.67405908 0.77440199 0.176826   0.08036772 0.00909012\n",
      "  0.35495671 0.55432181 0.99279771 0.1692256  0.03690108 0.08341613\n",
      "  0.21411401 0.44366764 0.152348   0.58297719 0.49090473 0.31181382\n",
      "  0.23577738 0.13224074 0.62074842 0.54795951 0.07432954 0.78303944\n",
      "  0.48774723 0.18749248 0.36618764 0.02638166 0.82247658 0.15944064\n",
      "  0.01777281 0.53140054 0.66061428 0.93751091 0.31606636 0.56341985\n",
      "  0.14131054 0.6372047  0.05883968 0.63111267 0.38493256 0.33363723\n",
      "  0.44941909 0.33834288]\n",
      " [0.78287971 0.9023123  0.76554064 0.24096218 0.91207525 0.49829968\n",
      "  0.05322931 0.49511398 0.9641632  0.58330645 0.30697617 0.59600876\n",
      "  0.2836104  0.23132556 0.75968394 0.13947111 0.14663889 0.56456342\n",
      "  0.49782652 0.87370993 0.03307117 0.20827811 0.18563628 0.81183822\n",
      "  0.80126333 0.88605238 0.89573521 0.87771352 0.60737839 0.83265245\n",
      "  0.26986301 0.36590414 0.82246263 0.94543869 0.15762427 0.97126567\n",
      "  0.61957986 0.52921971 0.53982782 0.72043916 0.72027735 0.55298153\n",
      "  0.09860973 0.52261143 0.68683663 0.6895671  0.54178701 0.7507829\n",
      "  0.29609119 0.89814964]\n",
      " [0.44039625 0.7467567  0.42463602 0.78980272 0.55677517 0.12167708\n",
      "  0.50794349 0.14227049 0.21365289 0.60096192 0.70974167 0.14740786\n",
      "  0.12584582 0.12560663 0.12797545 0.09092935 0.27862848 0.94286051\n",
      "  0.27002927 0.15573068 0.54071153 0.76879134 0.24518484 0.17803542\n",
      "  0.11457836 0.15961412 0.44265891 0.01450963 0.26347038 0.04213384\n",
      "  0.47652589 0.87108835 0.04637501 0.01321248 0.396728   0.18721494\n",
      "  0.52426619 0.72496655 0.60125492 0.84517345 0.61615384 0.7501927\n",
      "  0.5412668  0.28359036 0.25318769 0.18248496 0.93541746 0.68875209\n",
      "  0.2985109  0.42483118]\n",
      " [0.07771855 0.46209588 0.78131793 0.1618324  0.50064984 0.83946238\n",
      "  0.96724023 0.61756465 0.45785438 0.79769453 0.12250011 0.94089289\n",
      "  0.90281484 0.35338723 0.17130139 0.70145337 0.40372966 0.26121515\n",
      "  0.01460288 0.02280149 0.98934197 0.54304412 0.26253862 0.08769643\n",
      "  0.11879869 0.56562086 0.00498049 0.29061499 0.30943222 0.05161933\n",
      "  0.44627286 0.6320966  0.73568062 0.55948993 0.67286419 0.38290404\n",
      "  0.91623918 0.07487822 0.22332761 0.51857642 0.82559893 0.91649333\n",
      "  0.2365841  0.71133284 0.9434065  0.26730367 0.08473103 0.00676979\n",
      "  0.39546313 0.88056582]\n",
      " [0.89190277 0.93506802 0.05829847 0.66910872 0.8097394  0.04274758\n",
      "  0.75138013 0.21232454 0.41391939 0.10947398 0.07262413 0.21221596\n",
      "  0.56371181 0.51771335 0.62442424 0.68881587 0.00796662 0.94759494\n",
      "  0.49140945 0.30616629 0.65582078 0.59619414 0.3579522  0.14798796\n",
      "  0.70584034 0.19510373 0.35839092 0.51038467 0.07894851 0.9769727\n",
      "  0.10926136 0.7585496  0.60242443 0.38905531 0.70545734 0.63998182\n",
      "  0.4307837  0.93284532 0.19818553 0.21175684 0.03418077 0.93860665\n",
      "  0.93554516 0.10749747 0.43154096 0.98177168 0.05586294 0.65068559\n",
      "  0.6483024  0.04139629]\n",
      " [0.32013181 0.85904787 0.31727329 0.6821706  0.33011895 0.62068338\n",
      "  0.48490947 0.4274139  0.60101793 0.29316168 0.09922554 0.16763268\n",
      "  0.07362573 0.22742399 0.11610757 0.32625598 0.3049297  0.12516249\n",
      "  0.46673751 0.25085555 0.1559047  0.24898386 0.19843351 0.55229923\n",
      "  0.32690556 0.58169509 0.83855346 0.36308003 0.90110667 0.20789606\n",
      "  0.12753076 0.78634712 0.79228878 0.22880346 0.99213483 0.56946805\n",
      "  0.49865577 0.24868266 0.42320868 0.56033324 0.4314975  0.02741357\n",
      "  0.54590767 0.20006288 0.17465001 0.48813901 0.57229431 0.53484391\n",
      "  0.64864794 0.77927032]\n",
      " [0.21253177 0.85108355 0.52566366 0.78624158 0.98845882 0.67120237\n",
      "  0.89022059 0.20587854 0.06198327 0.23806814 0.89435023 0.74457883\n",
      "  0.50296021 0.99775072 0.52261132 0.29563845 0.08974632 0.13084198\n",
      "  0.15052272 0.44037865 0.06437639 0.29021178 0.24586039 0.85999794\n",
      "  0.34942355 0.45787752 0.13565797 0.68373828 0.26450391 0.51788037\n",
      "  0.56827051 0.73752935 0.97722082 0.75229799 0.60793588 0.26192033\n",
      "  0.19622909 0.30551938 0.17395591 0.41812469 0.77018463 0.17326449\n",
      "  0.12148742 0.80818012 0.43666124 0.15761782 0.22460375 0.86782072\n",
      "  0.08908233 0.53210483]\n",
      " [0.74439268 0.80186175 0.97024116 0.33296644 0.71672782 0.11765337\n",
      "  0.18333801 0.40409456 0.33966537 0.62094649 0.25270362 0.32436503\n",
      "  0.74114864 0.03211148 0.78550849 0.55668737 0.01237201 0.26203784\n",
      "  0.077527   0.07993663 0.75666247 0.06239673 0.09261524 0.54704678\n",
      "  0.59770584 0.18644165 0.72262805 0.7617903  0.9155177  0.55242171\n",
      "  0.00749242 0.7495977  0.01203321 0.29557709 0.37506864 0.81455363\n",
      "  0.44249403 0.49718899 0.20453667 0.01555428 0.18487412 0.60186075\n",
      "  0.53890935 0.80096556 0.34352355 0.193993   0.68336067 0.20008443\n",
      "  0.73299299 0.09498929]\n",
      " [0.09761468 0.29361212 0.11629271 0.52606097 0.92832656 0.76851198\n",
      "  0.642919   0.41294052 0.46846591 0.61615803 0.41955216 0.6974439\n",
      "  0.2218103  0.8675739  0.09679868 0.23320055 0.75914897 0.57638377\n",
      "  0.39698476 0.35827604 0.84430497 0.48754181 0.73751686 0.34427956\n",
      "  0.98528595 0.82052443 0.91510404 0.70600531 0.47483162 0.74905244\n",
      "  0.49472053 0.86475338 0.46238693 0.0370596  0.38757042 0.31566837\n",
      "  0.66120626 0.74009416 0.06316835 0.39516784 0.37804228 0.40715417\n",
      "  0.10965375 0.82521788 0.70018993 0.48721475 0.82738083 0.08216824\n",
      "  0.2450901  0.20997504]\n",
      " [0.28399594 0.99772628 0.93428307 0.02357067 0.7079165  0.04391671\n",
      "  0.20904951 0.4529171  0.31894706 0.97330181 0.3617386  0.77681203\n",
      "  0.45810502 0.38572288 0.27313253 0.61010717 0.213218   0.01881986\n",
      "  0.24428521 0.39763392 0.20328989 0.9372264  0.56462008 0.15647471\n",
      "  0.25659055 0.04629311 0.49559134 0.72788036 0.60149636 0.61725705\n",
      "  0.65294956 0.80276082 0.75450552 0.15713065 0.39684083 0.80486726\n",
      "  0.59040591 0.12209091 0.77790396 0.29074071 0.64784812 0.71846767\n",
      "  0.80506068 0.98001232 0.43247725 0.35465603 0.68404296 0.12073623\n",
      "  0.35708005 0.35096451]\n",
      " [0.46476472 0.55697379 0.49120988 0.6153712  0.04875834 0.74393067\n",
      "  0.97253668 0.1774929  0.88497609 0.4065516  0.39137929 0.16876203\n",
      "  0.32448956 0.40115052 0.4986459  0.02291451 0.20913368 0.77995467\n",
      "  0.42247458 0.90011017 0.25581614 0.87523485 0.92423453 0.2016247\n",
      "  0.48627959 0.78613131 0.65490213 0.79332091 0.99095594 0.01747732\n",
      "  0.00946343 0.76970336 0.70346404 0.73797394 0.63700538 0.4596093\n",
      "  0.31130063 0.16371403 0.07756244 0.09377995 0.12637423 0.06089371\n",
      "  0.72120448 0.98600789 0.47980259 0.04609591 0.92792993 0.74812407\n",
      "  0.30226008 0.22198481]\n",
      " [0.3169006  0.93809079 0.65995427 0.13646211 0.19854671 0.83745893\n",
      "  0.67104199 0.0010067  0.69016273 0.08085647 0.74881798 0.04556267\n",
      "  0.74111122 0.4259114  0.95312089 0.97616171 0.31259152 0.62043406\n",
      "  0.93594682 0.05058768 0.26232144 0.20467569 0.01731014 0.00385908\n",
      "  0.01426078 0.31515061 0.9422669  0.57080058 0.32350843 0.3836489\n",
      "  0.14946847 0.20099028 0.37066653 0.87155439 0.92171086 0.99038802\n",
      "  0.40472203 0.19691679 0.32925795 0.93880021 0.89949905 0.24465576\n",
      "  0.73045143 0.75621811 0.11440573 0.96484297 0.88860368 0.52066664\n",
      "  0.20663767 0.82701689]\n",
      " [0.67455455 0.22131546 0.822821   0.21753764 0.81855275 0.80330553\n",
      "  0.64435316 0.38370264 0.26865433 0.38289681 0.43153068 0.41936868\n",
      "  0.80492681 0.80652343 0.85307942 0.52383283 0.41559083 0.10045443\n",
      "  0.67305973 0.83268956 0.12318087 0.26000599 0.20507205 0.39776236\n",
      "  0.83830603 0.73997516 0.33036357 0.86455343 0.63851029 0.68718863\n",
      "  0.0165495  0.84023684 0.08366094 0.10513099 0.71584899 0.88291591\n",
      "  0.49800069 0.51825091 0.24853911 0.25325193 0.18505588 0.38679907\n",
      "  0.95161745 0.97359131 0.8340306  0.13460913 0.4240836  0.4882477\n",
      "  0.06322088 0.49858524]\n",
      " [0.2050737  0.26523225 0.03395488 0.07141305 0.2100502  0.61447006\n",
      "  0.13848725 0.44674658 0.21309341 0.63599751 0.73570453 0.90140728\n",
      "  0.92696685 0.46429458 0.67310139 0.46287512 0.49617408 0.84986978\n",
      "  0.49776333 0.12020037 0.26242579 0.0369578  0.29276991 0.74257378\n",
      "  0.3811051  0.08548329 0.02779517 0.98597188 0.93798934 0.70837614\n",
      "  0.13748975 0.57977426 0.99796526 0.40754178 0.50286086 0.07475609\n",
      "  0.19393485 0.08511157 0.40000922 0.01160085 0.92198686 0.3019509\n",
      "  0.60124442 0.47656498 0.46008719 0.9538062  0.04580679 0.90200833\n",
      "  0.74990191 0.41460745]]\n",
      "[[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 6.34701914e-02  6.57466394e-01  3.66263471e-01 -1.46875368e-01\n",
      "   -3.63751287e-02  1.09837252e-01 -3.65223642e-01 -5.31788596e-01\n",
      "   -5.60749104e-01  4.24135929e-01  6.29373950e-01  1.38317748e-01\n",
      "   -2.29110889e-01 -4.28715181e-01 -8.64822264e-01 -7.82962567e-02\n",
      "    2.41727396e-01  8.59444378e-01  5.59152580e-02 -2.87936960e-01\n",
      "    3.88363526e-01  1.85814147e-01 -2.45719889e-01 -1.33778401e-01\n",
      "   -1.21199026e-01  2.73733821e-02 -1.78089510e-01 -5.33449872e-01\n",
      "    1.89140836e-01 -7.40905594e-01 -1.12213386e-02  6.83595874e-01\n",
      "   -3.19812627e-01 -1.31691828e-02 -4.25748575e-01  2.77742971e-02\n",
      "    5.06493380e-01  1.93566012e-01 -5.93593641e-02 -9.23374584e-02\n",
      "    3.00087481e-01  1.86772844e-01  3.99956263e-01 -3.53614337e-01\n",
      "    1.94348008e-01 -4.48627713e-01  5.50484895e-01  3.55114860e-01\n",
      "   -1.50908192e-01  8.64882994e-02]\n",
      "  [-7.05161159e-01 -4.40216417e-01  1.57772908e-02 -7.91297801e-02\n",
      "   -4.11425410e-01  3.41162699e-01  9.14010921e-01  1.22450669e-01\n",
      "   -5.06308819e-01  2.14388081e-01 -1.84476061e-01  3.44884126e-01\n",
      "    6.19204444e-01  1.22061677e-01 -5.88382543e-01  5.61982263e-01\n",
      "    2.57090767e-01 -3.03348270e-01 -4.83223641e-01 -8.50908433e-01\n",
      "    9.56270804e-01  3.34766007e-01  7.69023412e-02 -7.24141797e-01\n",
      "   -6.82464633e-01 -3.20431516e-01 -8.90754721e-01 -5.87098527e-01\n",
      "   -2.97946171e-01 -7.81033112e-01  1.76409847e-01  2.66192462e-01\n",
      "   -8.67820054e-02 -3.85948756e-01  5.15239923e-01 -5.88361628e-01\n",
      "    2.96659317e-01 -4.54341495e-01 -3.16500211e-01 -2.01862740e-01\n",
      "    1.05321576e-01  3.63511797e-01  1.37974367e-01  1.88721405e-01\n",
      "    2.56569870e-01 -4.22263431e-01 -4.57055979e-01 -7.44013115e-01\n",
      "    9.93719413e-02 -1.75838269e-02]]\n",
      "\n",
      " [[ 5.14976708e-01  8.45777716e-01 -7.40739510e-05 -2.67569367e-01\n",
      "    2.16589099e-01  3.09077495e-02 -1.21787001e-01 -4.61734540e-01\n",
      "   -3.60482596e-01 -6.73520145e-02 -7.74359433e-03  2.03125848e-01\n",
      "    2.08755100e-01 -3.66084585e-02 -3.68373477e-01  5.19590265e-01\n",
      "   -2.89344595e-02  8.64178813e-01  2.77295433e-01 -1.37501354e-01\n",
      "    5.03472778e-01  1.32169480e-02 -1.32952533e-01 -1.63825864e-01\n",
      "    4.70062959e-01  6.28629864e-02 -2.62357503e-01 -3.75748377e-02\n",
      "    4.61896979e-03  1.93933261e-01 -3.78485867e-01  5.71057125e-01\n",
      "    2.36236792e-01  3.62673651e-01 -1.17019236e-01  4.80541178e-01\n",
      "    4.13010890e-01  4.01444777e-01 -4.62428756e-01 -7.25754073e-01\n",
      "   -2.81885591e-01  3.75186800e-01  7.94234620e-01 -5.29707231e-01\n",
      "    3.72701278e-01  3.50659007e-01 -3.29069620e-01  3.17048358e-01\n",
      "    1.98883314e-01 -2.96946588e-01]\n",
      "  [-4.62747900e-01 -4.32644332e-02 -4.48267350e-01  4.41208416e-01\n",
      "   -5.81956298e-01  1.22383702e-01  4.31680160e-01 -6.77000806e-02\n",
      "   -3.63145266e-01 -2.90144768e-01 -2.07750623e-01 -4.28376081e-01\n",
      "   -2.09984666e-01 -3.90156461e-03 -6.43576369e-01  1.86784872e-01\n",
      "    1.58290813e-01 -4.39400930e-01 -3.10890037e-02 -6.22854377e-01\n",
      "    1.22833528e-01  4.07057481e-02  1.27972274e-02 -2.59538994e-01\n",
      "   -4.74357765e-01 -3.04357288e-01 -5.71817468e-02 -5.14633490e-01\n",
      "    2.93728281e-01 -6.24756387e-01 -1.42332248e-01  4.20442986e-01\n",
      "   -3.01738507e-02 -7.16635226e-01  8.34510562e-01 -4.01797619e-01\n",
      "   -1.20924091e-01 -2.80537052e-01 -1.16619136e-01 -1.60105921e-01\n",
      "   -2.88779857e-01 -5.25567955e-01  4.47297940e-01 -3.22548546e-01\n",
      "   -5.12186620e-01 -2.01428093e-01  3.05073069e-02 -2.15938990e-01\n",
      "    3.52556755e-01 -1.18879328e-01]]\n",
      "\n",
      " [[-1.64394294e-01  7.61793250e-01  4.67291118e-01 -1.50436509e-01\n",
      "    3.95308519e-01  6.59362540e-01  1.70534632e-02 -4.68180544e-01\n",
      "   -7.12418717e-01  6.12421463e-02  8.13982507e-01  7.35488709e-01\n",
      "    1.48003506e-01  4.43428909e-01 -4.70186398e-01  1.26412845e-01\n",
      "    5.28452349e-02  4.74258501e-02 -6.35912941e-02 -3.28899200e-03\n",
      "   -8.79716128e-02 -2.92765416e-01 -2.45044345e-01  5.48184121e-01\n",
      "    1.13646167e-01  3.25636779e-01 -4.85090455e-01  1.35778771e-01\n",
      "    1.90174370e-01 -2.65159071e-01  8.05232826e-02  5.50036876e-01\n",
      "    6.11033183e-01  7.25916325e-01 -2.14540701e-01  1.02479687e-01\n",
      "    1.78456280e-01 -2.25881164e-01 -4.86658377e-01 -5.19386219e-01\n",
      "    4.54118268e-01 -3.90155365e-01 -1.98231227e-02  1.70975419e-01\n",
      "    3.77821560e-01 -4.73494853e-01 -1.60328817e-01  5.34183488e-01\n",
      "   -3.60336765e-01  1.93761946e-01]\n",
      "  [-3.84870249e-02 -1.00450554e-01  2.04700514e-01  9.20042630e-02\n",
      "   -1.95347433e-01 -3.80646313e-01  1.30108705e-01 -9.10194207e-02\n",
      "   -6.24497834e-01  3.76400441e-02 -5.42725430e-02 -2.71643728e-01\n",
      "    4.57538245e-01 -1.99214077e-01  2.58245493e-02  4.17216260e-01\n",
      "   -1.34266875e-01 -3.02525581e-01 -4.20299519e-01 -7.93773294e-01\n",
      "    7.23591304e-01 -1.45881380e-01 -9.30210366e-02 -2.64791447e-01\n",
      "   -2.03557489e-01 -6.99610729e-01 -1.73107161e-01 -1.15923217e-01\n",
      "    3.08139309e-01 -2.80230733e-01 -2.62370590e-01  3.83693563e-01\n",
      "   -8.10429417e-01 -6.49861598e-01  2.17444375e-01 -1.56712042e-01\n",
      "   -1.77085834e-01 -3.20307208e-02 -3.35291156e-01 -7.04884886e-01\n",
      "   -5.35403231e-01  4.88792182e-02  4.40299623e-01  2.78354133e-01\n",
      "   -3.43313076e-01 -4.95574106e-01  1.41573668e-01 -5.50698474e-01\n",
      "    4.36901807e-01 -8.03160358e-01]]\n",
      "\n",
      " [[-2.79311375e-01  2.04321814e-01  5.79201609e-02 -4.10617113e-01\n",
      "    3.35176264e-01  7.56672153e-01 -2.30248127e-01 -2.61118569e-01\n",
      "   -3.05936084e-01  4.39332030e-01  3.39184442e-01  6.88353780e-01\n",
      "   -1.33146404e-01  3.13252086e-01 -8.95999033e-01  6.39749433e-02\n",
      "    7.22247891e-01  4.92967636e-01  1.82870745e-01 -8.53916036e-02\n",
      "    6.91956962e-01 -9.54353880e-02  2.46612131e-01  3.24657423e-02\n",
      "    7.49508571e-01  6.88283692e-01  2.94355618e-01  1.58045801e-01\n",
      "    4.00502082e-01 -3.39870010e-02  6.97330250e-03  6.77260904e-01\n",
      "    9.61992979e-02  1.06779376e-02 -4.34906159e-01  1.56227726e-01\n",
      "    6.43433451e-01  2.08693619e-01 -5.97445931e-01 -5.42343074e-01\n",
      "    6.19759231e-02 -1.56265680e-01 -3.16567951e-02  1.88013187e-01\n",
      "    6.41350247e-01 -1.43897920e-01  4.42448267e-01 -2.51468997e-01\n",
      "   -2.04328988e-01 -1.28367842e-01]\n",
      "  [-4.98883765e-01  9.54139791e-02  1.68742424e-01 -2.17391511e-01\n",
      "   -2.04158747e-01 -4.54382974e-01  1.55820200e-01 -4.21968861e-02\n",
      "   -6.45216141e-01  3.89995369e-01  5.47624340e-02  1.80803272e-01\n",
      "    1.74494624e-01  1.54397329e-01 -4.86551410e-01  4.70636057e-01\n",
      "    6.65791111e-02 -5.45743568e-01 -2.53541303e-01 -4.76076009e-01\n",
      "    1.70218721e-01  7.28948293e-01  3.78983797e-01 -6.55363508e-01\n",
      "   -5.44672776e-01 -8.39759275e-01 -4.00143868e-01 -1.49833161e-01\n",
      "   -5.88203300e-03 -2.15395400e-01  3.83086548e-01  4.36856684e-01\n",
      "   -6.79571045e-02 -7.88308034e-01  2.39216562e-01 -1.66398414e-01\n",
      "   -2.91739506e-02 -4.07128809e-01  2.38076139e-01 -4.29698448e-01\n",
      "   -7.24292308e-02  1.65486145e-01  7.06450949e-01  4.57400885e-01\n",
      "   -2.54359380e-01 -3.34911067e-01  1.42255949e-01 -6.30046674e-01\n",
      "    6.09888593e-02 -5.47185136e-01]]\n",
      "\n",
      " [[ 8.78386566e-02  4.67683485e-01  4.32837335e-01 -3.21306881e-01\n",
      "   -5.44391956e-01  7.32090839e-01  9.93695523e-02 -4.96566189e-01\n",
      "    1.10574097e-01  2.29725608e-01  3.11011568e-01  1.59671913e-01\n",
      "   -3.04671460e-02 -1.53171286e-01 -4.94151815e-01 -1.46311093e-01\n",
      "    1.72232598e-01  6.96538536e-01  2.08360569e-01  4.56442532e-01\n",
      "    1.03468135e-01  2.92257652e-01  4.33329798e-01 -1.10189120e-01\n",
      "    2.50502205e-01  6.53890569e-01  3.41537119e-02  2.45361400e-01\n",
      "    9.16626397e-01 -7.65562121e-01 -4.78283796e-01  5.82210885e-01\n",
      "    3.37276408e-01  7.11592278e-01 -1.85471201e-01  3.00168663e-01\n",
      "    2.93527818e-01 -3.67686513e-01 -5.83051846e-01 -8.43730966e-01\n",
      "   -1.89692131e-01 -5.02526140e-01  5.79893937e-01  3.48803194e-01\n",
      "    4.20962903e-01 -5.85016763e-01  5.42997367e-01  4.14486839e-01\n",
      "   -1.47159007e-01 -1.16358070e-01]\n",
      "  [-4.65979105e-01  3.57784857e-02 -1.05586377e-01 -1.04500068e-01\n",
      "   -7.13528536e-01  3.39159249e-01  6.17812688e-01 -4.94107288e-01\n",
      "   -2.74000465e-01 -5.02449976e-01  4.41841808e-01 -5.50446094e-01\n",
      "    4.57500820e-01  1.94585846e-01  1.93436951e-01  8.36690597e-01\n",
      "    1.65952635e-01  5.58706359e-02  4.38120307e-01 -8.23122241e-01\n",
      "    2.29250276e-01 -3.60241735e-03 -1.68326139e-01 -8.07979146e-01\n",
      "   -7.87002544e-01 -5.70901766e-01  4.65316966e-02 -3.06912940e-01\n",
      "   -2.83869957e-01 -4.49003547e-01 -1.20394544e-01 -1.64913857e-01\n",
      "   -4.51796095e-01 -7.38842959e-02  7.64086591e-01  1.91223531e-02\n",
      "   -2.14857827e-01 -3.32302924e-01 -2.10569875e-01  2.18361044e-01\n",
      "    1.79221697e-01 -3.08325773e-01  6.31841700e-01  2.33606683e-01\n",
      "   -5.72430897e-01  2.75275867e-01  3.46816670e-01 -2.30116259e-01\n",
      "   -8.94535212e-02 -7.11327569e-02]]\n",
      "\n",
      " [[ 2.97628491e-01  1.32025158e-01  7.64448450e-01 -7.19140442e-01\n",
      "    2.25402455e-01  7.91465697e-01 -2.28813974e-01 -2.90356447e-01\n",
      "   -5.05747659e-01  2.06070813e-01  3.51162959e-01  4.10278567e-01\n",
      "    4.49970105e-01  2.52201617e-01 -1.39718292e-01  3.54607222e-01\n",
      "    3.78689744e-01  1.70382996e-02  4.58945718e-01  3.89021914e-01\n",
      "   -2.91671311e-02 -3.22971202e-01 -2.85832677e-01  8.59485401e-02\n",
      "    6.02528641e-01  6.07734418e-01 -2.90384854e-01  3.16593929e-01\n",
      "    5.64180749e-01 -9.58508118e-02 -4.71197726e-01  6.52744358e-01\n",
      "   -2.82526695e-01  7.87493289e-02 -1.06627591e-01  7.23475265e-01\n",
      "    4.80227879e-01 -1.31496292e-02 -4.12075173e-01 -6.84258985e-01\n",
      "   -1.31010479e-01 -1.76620786e-01  8.10306912e-01  3.36386616e-01\n",
      "    7.75190916e-01 -4.96503542e-01  3.91510329e-02  1.54610464e-01\n",
      "   -3.86198213e-01  1.60242358e-01]\n",
      "  [-5.77806013e-01 -6.37080052e-01 -7.31585759e-01 -1.69549124e-01\n",
      "   -7.02025050e-01  1.16170383e-01  8.52579470e-02 -4.83674056e-02\n",
      "   -7.51069793e-01  5.26910600e-02  4.28728359e-01  3.05398520e-01\n",
      "    6.43356459e-01  2.32969020e-01 -8.65825457e-02  3.23404010e-01\n",
      "    3.49535192e-01  2.85306362e-01 -6.31828551e-05 -7.53509553e-01\n",
      "    2.29354626e-01 -1.71320308e-01  1.07133632e-01 -6.92644398e-02\n",
      "   -4.20158221e-01 -8.00569093e-01 -8.67940038e-01  1.08258362e-01\n",
      "    3.30610947e-01 -1.24276310e-01 -1.32373262e-01  2.13870127e-01\n",
      "    1.75502630e-01 -5.37896909e-01  3.45236592e-01 -8.96509580e-01\n",
      "   -4.25645015e-01 -4.44108149e-01 -1.39818602e-01 -7.08838317e-01\n",
      "    2.01709507e-01 -2.51030632e-01  5.02634692e-01 -4.60464558e-02\n",
      "   -2.26749442e-01  2.64239101e-01 -4.95980217e-01  1.51225425e-01\n",
      "    4.53810724e-01 -4.83542194e-01]]]\n",
      "3.21464896202\n"
     ]
    }
   ],
   "source": [
    "'''FINAL SCRIPT'''\n",
    "\n",
    "'''To do:\n",
    "1) Integrate with model and within session\n",
    "1) Move stuff that can be moved outside loops\n",
    "2) Try not adding more nodes to the graph\n",
    "'''\n",
    "def get_encoder_reps(resultant_tensor, tensor_seq_lengths):\n",
    "    return tf.convert_to_tensor(np.random.random_sample((resultant_tensor.shape[0],50)))\n",
    "\n",
    "\n",
    "tf.InteractiveSession()\n",
    "\n",
    "'''INPUTS'''\n",
    "input_word_seq_tensor = tf.convert_to_tensor(np.array([[0,1,2,3,1,2],[9,10,11,12,13,12]]),dtype='int32')\n",
    "max_seq_length = 6\n",
    "enc_dims = 50\n",
    "seq_lengths = tf.convert_to_tensor(np.array([4,5]),dtype='int32') #shape n\n",
    "\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "'''Create mask based on max seq length'''\n",
    "np_mask_matrix = np.ones((max_seq_length,max_seq_length)) #num drops=n\n",
    "a = np.array(range(max_seq_length))\n",
    "np_mask_matrix[np.arange(len(a)), a] = 0\n",
    "#np_mask_matrix  = np_mask_matrix!=0\n",
    "tf_mask_matrix = tf.convert_to_tensor(np_mask_matrix, dtype=\"bool\")\n",
    "padding = tf.constant([[0,0],[0,1]],dtype='int32')\n",
    "resultant_tensor = tf.expand_dims(input_word_seq_tensor,0)\n",
    "#print(resultant_tensor.eval())\n",
    "tensor_seq_lengths = tf.expand_dims(seq_lengths, 0)\n",
    "seq_lengths_for_dropped = tf.expand_dims(seq_lengths-tf.ones(shape=seq_lengths.shape[0],dtype=\"int32\"),0)\n",
    "#print(seq_lengths_for_dropped)\n",
    "\n",
    "#def condition(x):\n",
    " #   x.shape[0]< max_seq_length\n",
    "#def body(x):\n",
    " #   Copy\n",
    "\n",
    "for drop_index in range(max_seq_length):\n",
    "    '''Create mask function-> note the drop index changes at each iteration'''\n",
    "    f = lambda word_seq: tf.boolean_mask(word_seq, tf_mask_matrix[:,drop_index])#,padding,\"CONSTANT\") \n",
    "    '''Apply masking and padding'''\n",
    "    #temp = tf.pad(tf.map_fn(f, input_word_seq_tensor), padding, \"CONSTANT\") #We apply mask and then pad result to enable concatenation with original \n",
    "    #temp = tf.expand_dims(temp,0)\n",
    "    resultant_tensor = tf.concat([resultant_tensor,tf.expand_dims(tf.pad(tf.map_fn(f, input_word_seq_tensor), padding, \"CONSTANT\"),0)],0)\n",
    "    tensor_seq_lengths = tf.concat([tensor_seq_lengths, seq_lengths_for_dropped],0)\n",
    "#print(resultant_tensor.eval())\n",
    "#print(resultant_tensor.shape)\n",
    "#print(tensor_seq_lengths.eval())\n",
    "#print(tensor_seq_lengths.shape)\n",
    "resultant_tensor = tf.reshape(resultant_tensor,[resultant_tensor.shape[0]*resultant_tensor.shape[1],resultant_tensor.shape[2]])\n",
    "tensor_seq_lengths = tf.reshape(tensor_seq_lengths,[tensor_seq_lengths.shape[0]*tensor_seq_lengths.shape[1],])\n",
    "#seq2seq_out = get_encoded_rep()\n",
    "#the seq2seq_out = reshaping of\n",
    "'''get_encoder_reps returns the batched encoder representations (shape = [(input_max_length+2)*(input_batch_size) , encoder_dims]'''\n",
    "x = get_encoder_reps(resultant_tensor,tensor_seq_lengths)\n",
    "seq2seq_out = tf.reshape(x, [max_seq_length+1, input_word_seq_tensor.shape[0], enc_dims])\n",
    "\n",
    "#Each column corresponds to the vector rep for a sentence\n",
    "#Each row corresponds to the word representation\n",
    "\n",
    "#We now reduce this by doing an op(row_0,row_i) for all columns\n",
    "'''NOTE : Hard coded here with subtract have to replace with op(row_0, row_i) for all rows i'''\n",
    "seq2seq_out = tf.subtract(seq2seq_out,seq2seq_out[0,:])[1:,:]\n",
    "#So final output should be max_seq_len*n_batches*dims --> do transpose if needed\n",
    "#seq2seq_out = tf.transpose(seq2seq_out,perm=[1,0,2]) #convert to n_batches*max_seq_len*dims or n_batches*words*dims\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#apply function operation that takes first index and performs op(first_index, slice)\n",
    "\n",
    "print(resultant_tensor.eval())\n",
    "print(tensor_seq_lengths.eval())\n",
    "#print(seq2seq_in.shape)\n",
    "#print(seq2seq_in_lengths.eval())\n",
    "#print(seq2seq_in_lengths.shape)\n",
    "print(x.eval())\n",
    "print(seq2seq_out.eval())\n",
    "\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "'''INPUTS'''\n",
    "input_word_seq_tensor = tf.convert_to_tensor(np.array([[0,1,2,3,1,2],[9,10,11,12,13,12]]),dtype='int32')\n",
    "max_seq_length = 6\n",
    "enc_dims = 50\n",
    "seq_lengths = tf.convert_to_tensor(np.array([4,5]),dtype='int32') #shape n\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''Create mask based on max seq length'''\n",
    "np_mask_matrix = np.ones((max_seq_length,max_seq_length)) #num drops=n\n",
    "a = np.array(range(max_seq_length))\n",
    "np_mask_matrix[np.arange(len(a)), a] = 0\n",
    "#np_mask_matrix  = np_mask_matrix!=0\n",
    "tf_mask_matrix = tf.convert_to_tensor(np_mask_matrix, dtype=\"bool\")\n",
    "padding = tf.constant([[0,0],[0,1]],dtype='int32')\n",
    "resultant_tensor = tf.expand_dims(input_word_seq_tensor,0)\n",
    "#print(resultant_tensor.eval())\n",
    "tensor_seq_lengths = tf.expand_dims(seq_lengths, 0)\n",
    "seq_lengths_for_dropped = tf.expand_dims(seq_lengths-tf.ones(shape=seq_lengths.shape[0],dtype=\"int32\"),0)\n",
    "#print(seq_lengths_for_dropped)\n",
    "\n",
    "#def condition(x):\n",
    " #   x.shape[0]< max_seq_length\n",
    "#def body(x):\n",
    " #   Copy\n",
    "\n",
    "for drop_index in range(max_seq_length):\n",
    "    '''Create mask function-> note the drop index changes at each iteration'''\n",
    "    f = lambda word_seq: tf.boolean_mask(word_seq, tf_mask_matrix[:,drop_index])#,padding,\"CONSTANT\") \n",
    "    '''Apply masking and padding'''\n",
    "    #temp = tf.pad(tf.map_fn(f, input_word_seq_tensor), padding, \"CONSTANT\") #We apply mask and then pad result to enable concatenation with original \n",
    "    #temp = tf.expand_dims(temp,0)\n",
    "    resultant_tensor = tf.concat([resultant_tensor,tf.expand_dims(tf.pad(tf.map_fn(f, input_word_seq_tensor), padding, \"CONSTANT\"),0)],0)\n",
    "    tensor_seq_lengths = tf.concat([tensor_seq_lengths, seq_lengths_for_dropped],0)\n",
    "#print(resultant_tensor.eval())\n",
    "#print(resultant_tensor.shape)\n",
    "#print(tensor_seq_lengths.eval())\n",
    "#print(tensor_seq_lengths.shape)\n",
    "resultant_tensor = tf.reshape(resultant_tensor,[resultant_tensor.shape[0]*resultant_tensor.shape[1],resultant_tensor.shape[2]])\n",
    "tensor_seq_lengths = tf.reshape(tensor_seq_lengths,[tensor_seq_lengths.shape[0]*tensor_seq_lengths.shape[1],])\n",
    "#seq2seq_out = get_encoded_rep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'transpose_4:0' shape=(2, 6, 50) dtype=float64>"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 20 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(2), Dimension(6), Dimension(50)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "seq2seq_out.eval()\n",
    "seq2seq_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''Inputs'''\n",
    "\n",
    "#Input1 is of shape num_sentences(N)*max_sequence_length(L) and Input 2 is of shape N, (contains sequence lengths)\n",
    "input_word_seq_tensor = tf.convert_to_tensor(np.array([[0,1,2,3,1,2],[1,2,3,4,3,2]]))\n",
    "max_seq_length = 6\n",
    "seq_lengths = None #shape n\n",
    "\n",
    "'''Create mask based on max seq length'''\n",
    "np_mask_matrix = np.ones((max_seq_length,max_seq_length)) #num drops=n\n",
    "a = np.array(range(max_seq_length))\n",
    "np_mask_matrix[np.arange(len(a)), a] = 0\n",
    "#np_mask_matrix  = np_mask_matrix!=0\n",
    "tf_mask_matrix = tf.convert_to_tensor(np_mask_matrix, dtype=\"bool\")\n",
    "\n",
    "padding = tf.constant([[0,0],[0,1]]) #remember it is of shape 1*dim_axis*2 (where the 2 are filled by paddings before and after)\n",
    "'''Mask function '''\n",
    "#below we first mask so N*max_sequence_length -> N*max_sequence_length-1\n",
    "#then we pad a single value of 0 to each column to make result of same shape as max_seq_length \n",
    "#Padding makes it again into N*max_sequence_length\n",
    "\n",
    "'''Resultant tensor: First we expand dimension and then in each loop concatenate a new row.\n",
    "Resultant tensor after processing will have shape (max_sequence_length+1)*num_sentences*max_sequence_length\n",
    "'''\n",
    "resultant_tensor = tf.expand_dims(input_word_seq_tensor,0)\n",
    "\n",
    "'''We store sequence lengths (useful for seq2seq) for each sequence in final_sequence-> if input was of shape num_sentences, after processing it will be of shape (max_seq_length+1)*num_sentences'''\n",
    "'''Basically if it were [2,2,3] then it would be [[2,2,3],[1,1,2],[1,1,2],[1,1,2]'''\n",
    "tensor_seq_lengths = tf.expand_dims(seq_lengths, 0)\n",
    "seq_lengths_for_dropped = tf.expand_dims(seq_lengths-tf.ones(shape=seq_lengths.shape[0]))\n",
    "\n",
    "\n",
    "for drop_index in range(max_seq_length):\n",
    "    '''Create mask function-> note the drop index changes at each iteration'''\n",
    "    f = lambda word_seq: tf.boolean_mask(word_seq, tf_mask_matrix[:,drop_index])#,padding,\"CONSTANT\") \n",
    "    '''Apply masking and padding'''\n",
    "    temp = tf.pad(tf.map_fn(f, input_word_seq_tensor), padding, \"CONSTANT\") #We apply mask and then pad result to enable concatenation with original \n",
    "    resultant_tensor = tf.concat(resultant_tensor,temp,0)\n",
    "    tensor_seq_lengths = tf.concat(tensor_seq_lengths, seq_lengths_for_dropped,0)\n",
    "\n",
    "\n",
    "\n",
    "#convert returned tensor into the form (n*num_sen, max_len)\n",
    "#give to seq2seq with seq_lens as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'ExpandDims_2:0' shape=(1, 2, 6) dtype=int64>,\n",
       " <tf.Tensor 'Const_25:0' shape=(2, 6) dtype=int64>)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultant_tensor = tf.expand_dims(input_word_seq_tensor,0)\n",
    "resultant_tensor, input_word_seq_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#below we first mask so N*max_sequence_length -> N*max_sequence_length-1\n",
    "#then we pad a single value of 0 to each column to make result of same shape as max_seq_length \n",
    "#Padding makes it again into N*max_sequence_length\n",
    "\n",
    "f = lambda word_seq: tf.boolean_mask(word_seq, tf_mask_matrix[:,0])#,padding,\"CONSTANT\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Pad_1:0' shape=(2, ?) dtype=int64>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input tensor is of shape n\n",
    "tensor = tf.convert_to_tensor(np.array([[0,1,2,3,1,2],[1,2,3,4,3,2]]))\n",
    "\n",
    "tf.pad(tf.map_fn(f, tensor), padding, \"CONSTANT\") #We apply mask and then pad result to enable concatenation with original \n",
    "\n",
    "\n",
    "tf.concatenat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shapes (2,) and (4,) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-a08b2806701b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboolean_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.pyc\u001b[0m in \u001b[0;36mboolean_mask\u001b[0;34m(tensor, mask, name)\u001b[0m\n\u001b[1;32m   1155\u001b[0m           \u001b[0;34m\"Number of mask dimensions must be specified, even if some dimensions\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m           \" are None.  E.g. shape=[None] is ok, but shape=None is not.\")\n\u001b[0;32m-> 1157\u001b[0;31m     \u001b[0mshape_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mndims_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m     \u001b[0mleading_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mndims_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.pyc\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    751\u001b[0m     \"\"\"\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shapes %s and %s are incompatible\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmost_specific_compatible_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (2,) and (4,) are incompatible"
     ]
    }
   ],
   "source": [
    "tensor = tf.convert_to_tensor(np.array([[0,1,2,3,1,2],[1,2,3,4,3,2]]))\n",
    "#mask = np.array([True, False, True, False])\n",
    "#tf.boolean_mask(tensor, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice_7:0' shape=(6,) dtype=bool>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_mask_matrix[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#convert input of batch_size*seq_length into 1*batch_size*seq_length\n",
    "input_seq_tensor = tf.expand_dims(input_seq_tensor,0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in range(seq_length):\n",
    "    tf.boolean_mask(input_seq_tensor, tf_mask_matrix[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 0, 0, 0],\n",
       "       [1, 2, 3, 0, 0, 0],\n",
       "       [1, 2, 3, 0, 0, 0],\n",
       "       [1, 2, 3, 0, 0, 0],\n",
       "       [1, 2, 3, 0, 0, 0],\n",
       "       [1, 2, 3, 0, 0, 0]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply the np mask matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tensor = x3\n",
    "mask = np_mask_matrix\n",
    "z = tf.boolean_mask(tensor, np_mask_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 0, 0, 0, 1, 3, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 3, 0, 0, 1, 2,\n",
       "       3, 0, 0, 1, 2, 3, 0, 0])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "z.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'boolean_mask_11/Gather:0' shape=(?,) dtype=float32>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable(tf.truncated_normal(shape=(seq_length,seq_length,)))\n",
    "tf_mask_matrix = tf.convert_to_tensor(np_mask_matrix, dtype=\"bool\")\n",
    "\n",
    "l = tf.boolean_mask(x,tf_mask_matrix)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x1 = np.array([[1,2,3,0,0,0],[3,4,5,6,0,0]])\n",
    "#First output of [[[2,3,0,0,0],[4,5,6,0,0]] 1,3,0,0,0 1,2,0,0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 2, 3, 0, 0, 0],\n",
       "        [1, 2, 3, 0, 0, 0],\n",
       "        [1, 2, 3, 0, 0, 0],\n",
       "        [1, 2, 3, 0, 0, 0],\n",
       "        [1, 2, 3, 0, 0, 0],\n",
       "        [1, 2, 3, 0, 0, 0]],\n",
       "\n",
       "       [[3, 4, 5, 6, 0, 0],\n",
       "        [3, 4, 5, 6, 0, 0],\n",
       "        [3, 4, 5, 6, 0, 0],\n",
       "        [3, 4, 5, 6, 0, 0],\n",
       "        [3, 4, 5, 6, 0, 0],\n",
       "        [3, 4, 5, 6, 0, 0]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = np.repeat(x1, [6,6], axis =0).reshape(-1,6,6)\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False,  True,  True,  True,  True,  True],\n",
       "       [ True, False,  True,  True,  True,  True],\n",
       "       [ True,  True, False,  True,  True,  True],\n",
       "       [ True,  True,  True, False,  True,  True],\n",
       "       [ True,  True,  True,  True, False,  True],\n",
       "       [ True,  True,  True,  True,  True, False]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_mask_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x1 = x1.reshape(1,2,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3],\n",
       "       [2, 4],\n",
       "       [3, 5]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[0,:,[0,1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mask_matrix = [[1,1,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "seq_length = 6\n",
    "np_mask_matrix = np.ones((seq_length,seq_length)) #num drops=n\n",
    "a = np.array(range(seq_length))\n",
    "#b = np.zeros((3, 4))\n",
    "np_mask_matrix[np.arange(len(a)), a] = 0\n",
    "np_mask_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np_mask_matrix = np_mask_matrix!=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Now given the input seq as a 3d tensor or 2d tensor, we apply mask in either step or we can form a repeat vector and apply the mask to the resultant matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice:0' shape=(10, 100) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "y.eval().shape\n",
    "y[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "o = tf.ones(shape=(100,))\n",
    "1 1 1 1 1 1 <- Num elements based on seq length\n",
    "0 1 1 1 1 1 \n",
    "1 0 1 1 1 1\n",
    "1 1 0 1 1 1 \n",
    "1 1 1 0 1 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ff065ef58c9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'Tensor' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "\"\"\"Inputs:\n",
    "Seq_len\n",
    "Seq indices\n",
    "\n",
    "Procedure:\n",
    "Word_dropped_matrix = []\n",
    "For i in seq_len:\n",
    "    1) Make mask for each step of len = seq_len\n",
    "    2) Apply mask to input seq row (entire row- each column) through above and map_fn in TF to produce the resultant\n",
    "    3) word_dropped_matrix[i] = Batchwise\n",
    "Resultant shape is seq_len*batch\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
