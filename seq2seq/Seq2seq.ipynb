{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### TF Seq2seq\n",
    "1) For seq2seq to work we need eos and pad tokens. We use pad as <UNK> since there are no major repurcussions, and eos is stored in vocab already. Unless, <UNK> has a particular embedding. \n",
    "2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('./sequence_tagging/model/')\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_embeddings(filename):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        filename: path to the npz file\n",
    "\n",
    "    Returns:\n",
    "        matrix of embeddings (np array)\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with np.load(filename) as data:\n",
    "            return data[\"embeddings\"]\n",
    "\n",
    "    except IOError:\n",
    "        raise MyIOError(filename)\n",
    "        \n",
    "def dataset_load(domain_tr_data_path, vocab_path):\n",
    "    with open(domain_tr_data_path,'r') as p1:\n",
    "        domain_tr_data = pickle.load(p1)\n",
    "    with open(vocab_path,'r') as p1:\n",
    "        vocab = pickle.load(p1)\n",
    "        \n",
    "    domain_tr_data = map(lambda x: x[0],domain_tr_data)\n",
    "    idd_domain_tr_data = map(lambda x: [vocab[word] for word in x], domain_tr_data)\n",
    "    return idd_domain_tr_data, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "domain_name = 'laptop'\n",
    "domain_tr_data_path = '../data/Final_joint_data_absa//Domains/Laptop/Normal__normal_training_list.pickle'\n",
    "embeddings_path = '../data/Embeddings/Pruned/np_glove_200d_trimmed.npz'\n",
    "embeddings_name = 'glove200d'\n",
    "vocab_path = '../data/vocab_to_id.pkl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(vocab_path,'r') as p1:\n",
    "        vocab = pickle.load(p1)\n",
    "word_embeddings_np = get_word_embeddings(embeddings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pad_token = '<START>' #This is due to a mistake on my part. Didn't store PAD in vocab, stored unkown-> might lead to ambiguity. So assume start == pad for now. Will edit vocab later\n",
    "eos_token = '<END>'\n",
    "PAD = vocab[pad_token]\n",
    "EOS = vocab[eos_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "input_embedding_size = 200\n",
    "encoder_hidden_units = 50 #100\n",
    "decoder_hidden_units = encoder_hidden_units*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "encoder_inputs_length = tf.placeholder(shape=(None,), dtype=tf.int32, name='encoder_inputs_length')\n",
    "decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "embeddings = tf.Variable(word_embeddings_np, name=\"word_embeds\",dtype=tf.float32, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.rnn import LSTMCell, LSTMStateTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "encoder_cell = LSTMCell(encoder_hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "((encoder_fw_outputs,\n",
    "  encoder_bw_outputs),\n",
    " (encoder_fw_final_state,\n",
    "  encoder_bw_final_state)) = (\n",
    "    tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_cell,\n",
    "                                    cell_bw=encoder_cell,\n",
    "                                    inputs=encoder_inputs_embedded,\n",
    "                                    sequence_length=encoder_inputs_length,\n",
    "                                    dtype=tf.float32, time_major=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3:0' shape=(?, ?, 50) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_fw_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ReverseSequence:0' shape=(?, ?, 50) dtype=float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_bw_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LSTMStateTuple(c=<tf.Tensor 'bidirectional_rnn/fw/fw/while/Exit_2:0' shape=(?, 50) dtype=float32>, h=<tf.Tensor 'bidirectional_rnn/fw/fw/while/Exit_3:0' shape=(?, 50) dtype=float32>),\n",
       " LSTMStateTuple(c=<tf.Tensor 'bidirectional_rnn/bw/bw/while/Exit_2:0' shape=(?, 50) dtype=float32>, h=<tf.Tensor 'bidirectional_rnn/bw/bw/while/Exit_3:0' shape=(?, 50) dtype=float32>))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_fw_final_state, encoder_bw_final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat_1:0' shape=(?, 100) dtype=float32>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs = tf.concat((encoder_fw_outputs, encoder_bw_outputs),2)\n",
    "\n",
    "encoder_final_state_c = tf.concat(\n",
    "    (encoder_fw_final_state.c, encoder_bw_final_state.c), 1)\n",
    "\n",
    "encoder_final_state_h = tf.concat(\n",
    "    (encoder_fw_final_state.h, encoder_bw_final_state.h), 1)\n",
    "\n",
    "encoder_final_state = LSTMStateTuple(\n",
    "    c=encoder_final_state_c,\n",
    "    h=encoder_final_state_h\n",
    ") #this is useful later\n",
    "\n",
    "encoder_final_state_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "encoder_concat_everything = tf.concat([encoder_final_state_c,encoder_final_state_h], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat_3:0' shape=(?, 200) dtype=float32>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_concat_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "decoder_cell = LSTMCell(decoder_hidden_units)\n",
    "encoder_max_time, batch_size = tf.unstack(tf.shape(encoder_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "decoder_lengths = encoder_inputs_length + 4 #3 additional "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_uniform([decoder_hidden_units, vocab_size], -1, 1), dtype=tf.float32)\n",
    "b = tf.Variable(tf.zeros([vocab_size]), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "eos_time_slice = EOS*tf.ones([batch_size], dtype=tf.int32, name='EOS')\n",
    "pad_time_slice = PAD*tf.ones([batch_size], dtype=tf.int32, name='PAD')\n",
    "\n",
    "eos_step_embedded = tf.nn.embedding_lookup(embeddings, eos_time_slice)\n",
    "pad_step_embedded = tf.nn.embedding_lookup(embeddings, pad_time_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def loop_fn_initial():\n",
    "    initial_elements_finished = (0 >= decoder_lengths)  # all False at the initial step\n",
    "    initial_input = eos_step_embedded\n",
    "    initial_cell_state = encoder_final_state\n",
    "    initial_cell_output = None\n",
    "    initial_loop_state = None  # we don't need to pass any additional information\n",
    "    return (initial_elements_finished,\n",
    "            initial_input,\n",
    "            initial_cell_state,\n",
    "            initial_cell_output,\n",
    "            initial_loop_state)\n",
    "\n",
    "def loop_fn_transition(time, previous_output, previous_state, previous_loop_state):\n",
    "\n",
    "    def get_next_input():\n",
    "        output_logits = tf.add(tf.matmul(previous_output, W), b)\n",
    "        prediction = tf.argmax(output_logits, axis=1)\n",
    "        next_input = tf.nn.embedding_lookup(embeddings, prediction)\n",
    "        return next_input\n",
    "    \n",
    "    elements_finished = (time >= decoder_lengths) # this operation produces boolean tensor of [batch_size]\n",
    "                                                  # defining if corresponding sequence has ended\n",
    "\n",
    "    finished = tf.reduce_all(elements_finished) # -> boolean scalar\n",
    "    input = tf.cond(finished, lambda: pad_step_embedded, get_next_input)\n",
    "    state = previous_state\n",
    "    output = previous_output\n",
    "    loop_state = None\n",
    "\n",
    "    return (elements_finished, \n",
    "            input,\n",
    "            state,\n",
    "            output,\n",
    "            loop_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def loop_fn(time, previous_output, previous_state, previous_loop_state):\n",
    "    if previous_state is None:    # time == 0\n",
    "        assert previous_output is None and previous_state is None\n",
    "        return loop_fn_initial()\n",
    "    else:\n",
    "        return loop_fn_transition(time, previous_output, previous_state, previous_loop_state)\n",
    "\n",
    "decoder_outputs_ta, decoder_final_state, _ = tf.nn.raw_rnn(decoder_cell, loop_fn)\n",
    "decoder_outputs = decoder_outputs_ta.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'TensorArrayStack/TensorArrayGatherV3:0' shape=(?, ?, 100) dtype=float32>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "decoder_max_steps, decoder_batch_size, decoder_dim = tf.unstack(tf.shape(decoder_outputs))\n",
    "decoder_outputs_flat = tf.reshape(decoder_outputs, (-1, decoder_dim))\n",
    "decoder_logits_flat = tf.add(tf.matmul(decoder_outputs_flat, W), b)\n",
    "decoder_logits = tf.reshape(decoder_logits_flat, (decoder_max_steps, decoder_batch_size, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "decoder_prediction = tf.argmax(decoder_logits, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 25\n",
    "num_epochs = 10\n",
    "\n",
    "def dataset_load(domain_tr_data_path, vocab_path):\n",
    "    with open(domain_tr_data_path,'r') as p1:\n",
    "        domain_tr_data = pickle.load(p1)\n",
    "    with open(vocab_path,'r') as p1:\n",
    "        vocab = pickle.load(p1)\n",
    "        \n",
    "    domain_tr_data = map(lambda x: x[0],domain_tr_data)\n",
    "    idd_domain_tr_data = map(lambda x: [vocab[word] for word in x], domain_tr_data)\n",
    "    return idd_domain_tr_data\n",
    "\n",
    "def get_holdout_data(idd_domain_tr_data, num=10):\n",
    "    '''Simple function to check if encoder is functioning properly'''\n",
    "    return idd_domain_tr_data[:num]\n",
    "\n",
    "def gen_batch(idd_data, batch_size):\n",
    "    np.random.shuffle(idd_data)\n",
    "    rem = len(idd_data)%batch_size\n",
    "    num_batches = (len(idd_data)/batch_size) \n",
    "    if rem>0:\n",
    "        num_batches = num_batches + 1\n",
    "    \n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        if(i == num_batches -1 and (not rem==0)):\n",
    "            yield(idd_data[i*batch_size:])\n",
    "        else:\n",
    "            yield(idd_data[i*batch_size:(i+1)*batch_size])\n",
    "            \n",
    "def batch_modify(inputs, max_sequence_length=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        inputs:\n",
    "            list of sentences (integer lists)\n",
    "        max_sequence_length:\n",
    "            integer specifying how large should `max_time` dimension be.\n",
    "            If None, maximum sequence length would be used\n",
    "    \n",
    "    Outputs:\n",
    "        inputs_time_major:\n",
    "            input sentences transformed into time-major matrix \n",
    "            (shape [max_time, batch_size]) padded with 0s\n",
    "        sequence_lengths:\n",
    "            batch-sized list of integers specifying amount of active \n",
    "            time steps in each input sequence\n",
    "    \"\"\"\n",
    "    \n",
    "    sequence_lengths = [len(seq) for seq in inputs]\n",
    "    batch_size = len(inputs)\n",
    "    \n",
    "    if max_sequence_length is None:\n",
    "        max_sequence_length = max(sequence_lengths)\n",
    "    \n",
    "    inputs_batch_major = np.zeros(shape=[batch_size, max_sequence_length], dtype=np.int32) # == PAD\n",
    "    \n",
    "    for i, seq in enumerate(inputs):\n",
    "        for j, element in enumerate(seq):\n",
    "            inputs_batch_major[i, j] = element\n",
    "\n",
    "    # [batch_size, max_time] -> [max_time, batch_size]\n",
    "    inputs_time_major = inputs_batch_major.swapaxes(0, 1)\n",
    "\n",
    "    return inputs_time_major, sequence_lengths\n",
    "        \n",
    "def next_feed(batch):\n",
    "    encoder_inputs_, encoder_input_lengths_ = batch_modify(batch)\n",
    "    decoder_targets_, _ = batch_modify(\n",
    "        [(sequence) + [EOS] + [PAD] * 3 for sequence in batch] #additional 3 spaces\n",
    "    )\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        encoder_inputs_length: encoder_input_lengths_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }\n",
    "\n",
    "def feed_enc(enc_batch):\n",
    "    encoder_inputs_, encoder_input_lengths_ = batch_modify(enc_batch)\n",
    "    return {encoder_inputs: encoder_inputs_,\n",
    "            encoder_inputs_length: encoder_input_lengths_}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "idd_data = dataset_load(domain_tr_data_path,vocab_path)\n",
    "holdout_data = get_holdout_data(idd_data,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "embed_type = \"Glove\"\n",
    "model_path = '../results/seq2seq/{}_seq2seqmodel_embeds{}_{}d_{}hiddenunits.ckpt'.format(domain_name,embed_type,input_embedding_size,encoder_hidden_units)\n",
    "\n",
    "batch_size = 150\n",
    "lr = None\n",
    "num_epochs = 1\n",
    "model_exists_already = False\n",
    "\n",
    "if (lr is None):\n",
    "    train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "else:\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)\n",
    "\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = tf.get_default_graph()\n",
    "config = tf.ConfigProto(device_count={'GPU': 0})\n",
    "saver = tf.train.Saver()\n",
    "encoder_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "loss_track = []\n",
    "\n",
    "def train_graph(model_exists_already):\n",
    "    \n",
    "    with tf.Session(config=config) as sess:\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        print(\"Initialized session\")\n",
    "        if(model_exists_already):\n",
    "            print(\"loading existing model\")\n",
    "            saver.restore(sess, model_path)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(\"At epoch: {}\".format(epoch))\n",
    "            iters = 0 \n",
    "            epoch_loss = 0.\n",
    "            batch_generator = gen_batch(idd_data, batch_size)\n",
    "            for batch in batch_generator:\n",
    "                \n",
    "                fd = next_feed(batch)\n",
    "                _, l = sess.run([train_op, loss], fd)\n",
    "    \n",
    "                if(iters%33==0):\n",
    "                    print(\"At batch: {}\".format(iters))\n",
    "                    print(\"Batch loss: {}\".format(l))\n",
    "                loss_track.append(l)\n",
    "                iters+=1\n",
    "                epoch_loss+=l\n",
    "            print(\"Epoch training loss: {}\".format(epoch_loss/iters))\n",
    "            \n",
    "        f_enc = feed_enc(holdout_data)\n",
    "        encoder_useful_state = sess.run(encoder_concat_everything, f_enc)\n",
    "            \n",
    "        saver.save(sess,model_path)\n",
    "        print(\"Saved model at: {}\".format(model_path))\n",
    "        #encoder_useful_state = sess.run(encoder_concat_everything)\n",
    "    return encoder_useful_state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized session\n",
      "At epoch: 0\n",
      "0\n",
      "At batch: 0\n",
      "Batch loss: 8.94123077393\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "Epoch training loss: 8.67789202645\n",
      "Saved model at: ../results/seq2seq/laptop_seq2seqmodel_embedsGlove_200d_50hiddenunits.ckpt\n"
     ]
    }
   ],
   "source": [
    "encoder_out = train_graph(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03974946,  0.13104852, -0.15653771, ..., -0.06743222,\n",
       "         0.17112713,  0.6098332 ],\n",
       "       [-0.12657294,  0.3494651 , -0.02483254, ..., -0.04309835,\n",
       "         0.16275495,  0.5704211 ],\n",
       "       [ 0.01887111,  0.35905957, -0.22151423, ..., -0.07891329,\n",
       "        -0.06936573,  0.44957113],\n",
       "       ...,\n",
       "       [-0.20589386, -0.14179042, -0.11227965, ..., -0.2480825 ,\n",
       "        -0.0198348 ,  0.38863584],\n",
       "       [-0.00574304,  0.40867656, -0.02486085, ..., -0.07106452,\n",
       "         0.14196876,  0.6010943 ],\n",
       "       [-0.12318017,  0.2642312 , -0.45233864, ..., -0.13476329,\n",
       "         0.07698715,  0.4307763 ]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.97494584e-02,  1.31048515e-01, -1.56537712e-01,  9.37305212e-01,\n",
       "        1.85016558e-01, -2.25092173e-01, -1.24445307e+00, -8.87932420e-01,\n",
       "       -2.27239355e-02,  1.82536650e+00, -1.16929698e+00,  6.41500652e-02,\n",
       "        7.82994688e-01,  7.97010601e-01, -2.96856618e+00,  1.25599658e+00,\n",
       "        1.26194859e+00, -1.66895700e+00, -3.04197359e+00, -6.65612936e-01,\n",
       "        6.79446697e-01,  1.16614021e-01, -5.56325763e-02, -5.54149365e-03,\n",
       "       -8.14260364e-01,  1.63301587e+00,  5.53404152e-01, -3.52173522e-02,\n",
       "       -6.87773645e-01, -1.42797542e+00,  9.68344152e-01,  3.15772325e-01,\n",
       "        3.19913998e-02,  1.56362402e+00,  1.11489224e+00,  5.61491609e-01,\n",
       "        1.49946332e+00,  1.99195459e-01,  8.97922695e-01,  1.07440539e-02,\n",
       "        1.04080009e+00,  3.93972397e-01,  2.84967244e-01, -2.83503324e-01,\n",
       "        3.20904088e+00,  1.52513731e+00, -7.99509764e-01, -4.63211238e-02,\n",
       "       -8.66600126e-02,  8.65750253e-01, -7.38304555e-02,  2.60569870e-01,\n",
       "       -5.19262910e-01,  5.93699634e-01,  4.11177188e-01,  1.67241283e-02,\n",
       "       -9.37569082e-01, -1.28007662e+00, -4.10964414e-02,  1.79896855e+00,\n",
       "       -1.45390940e+00, -3.91762584e-01,  5.18890083e-01,  1.68168616e+00,\n",
       "       -2.99557137e+00,  1.33407736e+00,  1.32385516e+00, -1.75635552e+00,\n",
       "       -3.55736780e+00, -1.11481977e+00,  7.76424050e-01,  3.94636482e-01,\n",
       "       -4.42204662e-02, -2.13644236e-01, -1.66675851e-01,  1.68100119e+00,\n",
       "        8.81491303e-01, -9.74463463e-01, -1.42208874e-01, -1.69385326e+00,\n",
       "        1.54880500e+00, -2.02133954e-01,  6.29589081e-01,  2.40767336e+00,\n",
       "        6.76931977e-01,  1.01236296e+00,  1.64581788e+00,  1.18049726e-01,\n",
       "        1.74880779e+00,  1.19975135e-01,  1.44571900e+00,  3.96933734e-01,\n",
       "        7.73703381e-02, -5.04372120e-02,  3.75156927e+00,  1.38945830e+00,\n",
       "       -7.66879320e-01, -2.45350882e-01,  4.42524821e-01,  1.61375475e+00,\n",
       "       -2.28268951e-02,  6.52073249e-02, -9.90230814e-02,  2.95326471e-01,\n",
       "        8.09553638e-02, -1.05206326e-01, -4.36359197e-01, -3.78268450e-01,\n",
       "       -9.83379502e-03,  5.55878222e-01, -4.57699984e-01,  3.39822769e-02,\n",
       "        3.60377491e-01,  3.68699849e-01, -6.13347232e-01,  4.40741032e-01,\n",
       "        4.64816779e-01, -4.08884019e-01, -6.55274451e-01, -2.97613293e-01,\n",
       "        3.31177413e-01,  5.79283610e-02, -3.03354897e-02, -2.54119467e-03,\n",
       "       -3.47380370e-01,  5.27388573e-01,  2.85393238e-01, -1.77718420e-02,\n",
       "       -3.24152738e-01, -3.62196088e-01,  4.68044817e-01,  1.40416473e-01,\n",
       "        1.44680142e-02,  4.21577930e-01,  4.28303123e-01,  2.84142107e-01,\n",
       "        5.45214891e-01,  9.18844342e-02,  3.95866960e-01,  6.75363047e-03,\n",
       "        3.66262794e-01,  2.24110365e-01,  1.21865861e-01, -1.26307577e-01,\n",
       "        5.42177856e-01,  5.08665979e-01, -3.45551372e-01, -2.14450080e-02,\n",
       "       -4.15744297e-02,  4.00362968e-01, -3.12794968e-02,  1.77008763e-01,\n",
       "       -3.42285931e-01,  2.65698403e-01,  9.11649615e-02,  2.93031684e-03,\n",
       "       -3.52488101e-01, -5.59058070e-01, -2.00865772e-02,  3.22910935e-01,\n",
       "       -5.64560771e-01, -2.25807399e-01,  9.83059555e-02,  5.45629799e-01,\n",
       "       -3.97735357e-01,  4.89561975e-01,  6.32531464e-01, -5.13386369e-01,\n",
       "       -8.64020526e-01, -4.95294541e-01,  4.96179879e-01,  1.66785210e-01,\n",
       "       -2.93373130e-02, -7.89361894e-02, -5.68814985e-02,  5.99378943e-01,\n",
       "        5.71467400e-01, -4.56388742e-01, -1.20764479e-01, -4.70999777e-01,\n",
       "        5.74512482e-01, -8.42317045e-02,  1.35906130e-01,  2.24807948e-01,\n",
       "        2.71612346e-01,  6.28340781e-01,  7.87582517e-01,  2.62205340e-02,\n",
       "        6.43866539e-01,  6.03905544e-02,  4.67019916e-01,  2.45312259e-01,\n",
       "        2.50982530e-02, -1.83945447e-02,  8.72639358e-01,  3.55214328e-01,\n",
       "       -3.98248672e-01, -6.74322173e-02,  1.71127126e-01,  6.09833181e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Cell to continue training\\nwith tf.Session(config=config) as sess:\\n    #saver = tf.train.import_meta_graph('../results/seq2seq/laptop_seq2seqmodel_embedsGlove_200d_100hiddenunits.meta')\\n    #saver.restore(sess, tf.train.latest_checkpoint('../results/seq2seq/laptop_seq2seqmodel_embedsGlove_200d_100hiddenunits.data-00000-of-00001'))\\n    #sess.run()\\n    saver.restore(sess, model_path)\\n    batch_generator = gen_batch(idd_data, batch_size)\\n    for batch in batch_generator:        \\n        fd = next_feed(batch)\\n        _, l = sess.run([train_op, loss], fd)\\n        encoder_useful_state = sess.run(encoder_concat_everything, fd)\\n        \\n        \""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Cell to continue training'''\n",
    "with tf.Session(config=config) as sess:\n",
    "    #saver = tf.train.import_meta_graph('../results/seq2seq/laptop_seq2seqmodel_embedsGlove_200d_100hiddenunits.meta')\n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('../results/seq2seq/laptop_seq2seqmodel_embedsGlove_200d_100hiddenunits.data-00000-of-00001'))\n",
    "    #sess.run()\n",
    "    saver.restore(sess, model_path)\n",
    "    batch_generator = gen_batch(idd_data, batch_size)\n",
    "    for batch in batch_generator:        \n",
    "        fd = next_feed(batch)\n",
    "        _, l = sess.run([train_op, loss], fd)\n",
    "        encoder_useful_state = sess.run(encoder_concat_everything, fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''Cell to test in format for experiment'''\n",
    "def restored_model_enc_out(model_exists_already=True):\n",
    "    with tf.Session(config=config) as sess:\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        print(\"Initialized session\")\n",
    "        if(model_exists_already):\n",
    "            print(\"loading existing model\")\n",
    "            saver.restore(sess, model_path)\n",
    "        \n",
    "       \n",
    "        f_enc = feed_enc(holdout_data)\n",
    "        encoder_useful_state = sess.run(encoder_concat_everything, f_enc)\n",
    "            \n",
    "        #encoder_useful_state = sess.run(encoder_concat_everything)\n",
    "    return encoder_useful_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized session\n",
      "loading existing model\n",
      "INFO:tensorflow:Restoring parameters from ../results/seq2seq/laptop_seq2seqmodel_embedsGlove_200d_50hiddenunits.ckpt\n"
     ]
    }
   ],
   "source": [
    "encoder_useful_state = restored_model_enc_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03974946,  0.13104852, -0.15653771, ..., -0.06743222,\n",
       "         0.17112713,  0.6098332 ],\n",
       "       [-0.12657294,  0.3494651 , -0.02483254, ..., -0.04309835,\n",
       "         0.16275495,  0.5704211 ],\n",
       "       [ 0.01887111,  0.35905957, -0.22151423, ..., -0.07891329,\n",
       "        -0.06936573,  0.44957113],\n",
       "       ...,\n",
       "       [-0.20589386, -0.14179042, -0.11227965, ..., -0.2480825 ,\n",
       "        -0.0198348 ,  0.38863584],\n",
       "       [-0.00574304,  0.40867656, -0.02486085, ..., -0.07106452,\n",
       "         0.14196876,  0.6010943 ],\n",
       "       [-0.12318017,  0.2642312 , -0.45233864, ..., -0.13476329,\n",
       "         0.07698715,  0.4307763 ]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_useful_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
