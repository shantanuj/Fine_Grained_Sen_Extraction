{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''FINAL SCRIPT'''\n",
    "\n",
    "'''To do:\n",
    "1) Integrate with model and within session\n",
    "1) Move stuff that can be moved outside loops\n",
    "2) Try not adding more nodes to the graph\n",
    "'''\n",
    "def get_encoder_reps(resultant_tensor, tensor_seq_lengths):\n",
    "    return tf.convert_to_tensor(np.random.random_sample((resultant_tensor.shape[0],50)))\n",
    "\n",
    "\n",
    "tf.InteractiveSession()\n",
    "\n",
    "'''INPUTS'''\n",
    "input_word_seq_tensor = tf.convert_to_tensor(np.array([[0,1,2,3,1,2],[9,10,11,12,13,12]]),dtype='int32')\n",
    "max_seq_length = 6\n",
    "enc_dims = 50\n",
    "seq_lengths = tf.convert_to_tensor(np.array([4,5]),dtype='int32') #shape n\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''Create mask based on max seq length'''\n",
    "np_mask_matrix = np.ones((max_seq_length,max_seq_length)) #num drops=n\n",
    "a = np.array(range(max_seq_length))\n",
    "np_mask_matrix[np.arange(len(a)), a] = 0\n",
    "#np_mask_matrix  = np_mask_matrix!=0\n",
    "tf_mask_matrix = tf.convert_to_tensor(np_mask_matrix, dtype=\"bool\")\n",
    "padding = tf.constant([[0,0],[0,1]],dtype='int32')\n",
    "resultant_tensor = tf.expand_dims(input_word_seq_tensor,0)\n",
    "#print(resultant_tensor.eval())\n",
    "tensor_seq_lengths = tf.expand_dims(seq_lengths, 0)\n",
    "seq_lengths_for_dropped = tf.expand_dims(seq_lengths-tf.ones(shape=seq_lengths.shape[0],dtype=\"int32\"),0)\n",
    "#print(seq_lengths_for_dropped)\n",
    "\n",
    "#def condition(x):\n",
    " #   x.shape[0]< max_seq_length\n",
    "#def body(x):\n",
    " #   Copy\n",
    "\n",
    "for drop_index in range(max_seq_length):\n",
    "    '''Create mask function-> note the drop index changes at each iteration'''\n",
    "    f = lambda word_seq: tf.boolean_mask(word_seq, tf_mask_matrix[:,drop_index])#,padding,\"CONSTANT\") \n",
    "    '''Apply masking and padding'''\n",
    "    #temp = tf.pad(tf.map_fn(f, input_word_seq_tensor), padding, \"CONSTANT\") #We apply mask and then pad result to enable concatenation with original \n",
    "    #temp = tf.expand_dims(temp,0)\n",
    "    resultant_tensor = tf.concat([resultant_tensor,tf.expand_dims(tf.pad(tf.map_fn(f, input_word_seq_tensor), padding, \"CONSTANT\"),0)],0)\n",
    "    tensor_seq_lengths = tf.concat([tensor_seq_lengths, seq_lengths_for_dropped],0)\n",
    "#print(resultant_tensor.eval())\n",
    "#print(resultant_tensor.shape)\n",
    "#print(tensor_seq_lengths.eval())\n",
    "#print(tensor_seq_lengths.shape)\n",
    "resultant_tensor = tf.reshape(resultant_tensor,[resultant_tensor.shape[0]*resultant_tensor.shape[1],resultant_tensor.shape[2]])\n",
    "tensor_seq_lengths = tf.reshape(tensor_seq_lengths,[tensor_seq_lengths.shape[0]*tensor_seq_lengths.shape[1],])\n",
    "#seq2seq_out = get_encoded_rep()\n",
    "#the seq2seq_out = reshaping of\n",
    "'''get_encoder_reps returns the batched encoder representations (shape = [(input_max_length+2)*(input_batch_size) , encoder_dims]'''\n",
    "#x = get_encoder_reps(resultant_tensor,tensor_seq_lengths,dims)\n",
    "seq2seq_out = tf.reshape(get_encoder_reps(resultant_tensor,tensor_seq_lengths), [max_seq_length+1, input_word_seq_tensor.shape[0], enc_dims])\n",
    "\n",
    "#Each column corresponds to the vector rep for a sentence\n",
    "#Each row corresponds to the word representation\n",
    "\n",
    "#We now reduce this by doing an op(row_0,row_i) for all columns\n",
    "'''NOTE : Hard coded here with subtract have to replace with op(row_0, row_i) for all rows i'''\n",
    "seq2seq_out = tf.subtract(seq2seq_out,seq2seq_out[0,:])[1:,:]\n",
    "#So final output should be max_seq_len*n_batches*dims --> do transpose if needed\n",
    "seq2seq_out = tf.transpose(seq2seq_out,perm=[1,0,2]) #convert to n_batches*max_seq_len*dims or n_batches*words*dims\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#apply function operation that takes first index and performs op(first_index, slice)\n",
    "#print(seq2seq_in.eval())\n",
    "#print(seq2seq_in.shape)\n",
    "#print(seq2seq_in_lengths.eval())\n",
    "#print(seq2seq_in_lengths.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Given a tensor like [[1,2,3,0,0,0],[3,4,5,6,0,0]]\n",
    "#convert to [[[1,2,3,0,0,0],[2,3,0,0,0],[1,3,0,0,0],[1,2,0,0,0],etc]]\n",
    "\n",
    "#We first output for lengths of n again (where n is max length)\n",
    "#Then we concat to original column\n",
    "\n",
    "\n",
    "#IN seq2seq processing, make sure to read in the seq_length.<- Very imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#We plan to apply a map_fn to each which does that\n",
    "#The map_fn creates a new batch by applying ignore given indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[0, 1, 2, 3, 1, 2],\n",
      "        [1, 2, 3, 4, 3, 2]],\n",
      "\n",
      "       [[1, 2, 3, 1, 2, 0],\n",
      "        [2, 3, 4, 3, 2, 0]],\n",
      "\n",
      "       [[0, 2, 3, 1, 2, 0],\n",
      "        [1, 3, 4, 3, 2, 0]],\n",
      "\n",
      "       [[0, 1, 3, 1, 2, 0],\n",
      "        [1, 2, 4, 3, 2, 0]],\n",
      "\n",
      "       [[0, 1, 2, 1, 2, 0],\n",
      "        [1, 2, 3, 3, 2, 0]],\n",
      "\n",
      "       [[0, 1, 2, 3, 2, 0],\n",
      "        [1, 2, 3, 4, 2, 0]],\n",
      "\n",
      "       [[0, 1, 2, 3, 1, 0],\n",
      "        [1, 2, 3, 4, 3, 0]]], dtype=int32), array([[4, 5],\n",
      "       [3, 4],\n",
      "       [3, 4],\n",
      "       [3, 4],\n",
      "       [3, 4],\n",
      "       [3, 4],\n",
      "       [3, 4]], dtype=int32), 6)\n"
     ]
    }
   ],
   "source": [
    "tf.InteractiveSession()\n",
    "input_word_seq_tensor = tf.convert_to_tensor(np.array([[0,1,2,3,1,2],[1,2,3,4,3,2]]),dtype='int32')\n",
    "max_seq_length = 6\n",
    "seq_lengths = tf.convert_to_tensor(np.array([4,5]),dtype='int32') #shape n\n",
    "'''Create mask based on max seq length'''\n",
    "np_mask_matrix = np.ones((max_seq_length,max_seq_length)) #num drops=n\n",
    "a = np.array(range(max_seq_length))\n",
    "np_mask_matrix[np.arange(len(a)), a] = 0\n",
    "#np_mask_matrix  = np_mask_matrix!=0\n",
    "tf_mask_matrix = tf.convert_to_tensor(np_mask_matrix, dtype=\"bool\")\n",
    "padding = tf.constant([[0,0],[0,1]],dtype='int32')\n",
    "resultant_tensor = tf.expand_dims(input_word_seq_tensor,0)\n",
    "#print(resultant_tensor.eval())\n",
    "tensor_seq_lengths = tf.expand_dims(seq_lengths, 0)\n",
    "seq_lengths_for_dropped = tf.expand_dims(seq_lengths-tf.ones(shape=seq_lengths.shape[0],dtype=\"int32\"),0)\n",
    "\n",
    "drop_index = tf.constant(0)\n",
    "\n",
    "def condition(resultant_tensor, tensor_seq_lengths,drop_index):\n",
    "    return drop_index< max_seq_length\n",
    "\n",
    "def body(resultant_tensor, tensor_seq_lengths,drop_index):\n",
    "    f = lambda word_seq: tf.boolean_mask(word_seq, tf_mask_matrix[:,drop_index])#,padding,\"CONSTANT\") \n",
    "    '''Apply masking and padding'''\n",
    "    temp = tf.pad(tf.map_fn(f, input_word_seq_tensor), padding, \"CONSTANT\") #We apply mask and then pad result to enable concatenation with original \n",
    "    temp = tf.expand_dims(temp,0)\n",
    "    resultant_tensor = tf.concat([resultant_tensor,temp],0)\n",
    "    tensor_seq_lengths = tf.concat([tensor_seq_lengths, seq_lengths_for_dropped],0)\n",
    "    drop_index+=1\n",
    "    return resultant_tensor, tensor_seq_lengths, drop_index\n",
    "\n",
    "result = resultant_tensor, tensor_seq_lengths, drop_index = tf.while_loop(condition, \n",
    "                                                                 body, \n",
    "                                                                 [resultant_tensor, tensor_seq_lengths,0], \n",
    "                                                                 shape_invariants= [tf.TensorShape([None,input_word_seq_tensor.shape[0],max_seq_length]),tf.TensorShape([None,input_word_seq_tensor.shape[0],]),drop_index.get_shape()])\n",
    "\n",
    "print(resultant_tensor.eval(), tensor_seq_lengths.eval(), drop_index.eval())\n",
    "#resultant_tensor, tensor_seq_lengths, drop_index = ([resultant_tensor, tensor_seq_lengths, drop_index])\n",
    "#seq2seq_in = tf.reshape(resultant_tensor,[resultant_tensor.shape[0]*resultant_tensor.shape[1],resultant_tensor.shape[2]])\n",
    "#seq2seq_in_lengths = tf.reshape(tensor_seq_lengths,[tensor_seq_lengths.shape[0]*tensor_seq_lengths.shape[1],])\n",
    "\n",
    "#print(seq2seq_in.eval())\n",
    "#print(seq2seq_in.shape)\n",
    "#print(seq2seq_in_lengths.eval())\n",
    "#print(seq2seq_in_lengths.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'transpose_4:0' shape=(2, 6, 50) dtype=float64>"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 20 Âµs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(2), Dimension(6), Dimension(50)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "seq2seq_out.eval()\n",
    "seq2seq_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''Inputs'''\n",
    "\n",
    "#Input1 is of shape num_sentences(N)*max_sequence_length(L) and Input 2 is of shape N, (contains sequence lengths)\n",
    "input_word_seq_tensor = tf.convert_to_tensor(np.array([[0,1,2,3,1,2],[1,2,3,4,3,2]]))\n",
    "max_seq_length = 6\n",
    "seq_lengths = None #shape n\n",
    "\n",
    "'''Create mask based on max seq length'''\n",
    "np_mask_matrix = np.ones((max_seq_length,max_seq_length)) #num drops=n\n",
    "a = np.array(range(max_seq_length))\n",
    "np_mask_matrix[np.arange(len(a)), a] = 0\n",
    "#np_mask_matrix  = np_mask_matrix!=0\n",
    "tf_mask_matrix = tf.convert_to_tensor(np_mask_matrix, dtype=\"bool\")\n",
    "\n",
    "padding = tf.constant([[0,0],[0,1]]) #remember it is of shape 1*dim_axis*2 (where the 2 are filled by paddings before and after)\n",
    "'''Mask function '''\n",
    "#below we first mask so N*max_sequence_length -> N*max_sequence_length-1\n",
    "#then we pad a single value of 0 to each column to make result of same shape as max_seq_length \n",
    "#Padding makes it again into N*max_sequence_length\n",
    "\n",
    "'''Resultant tensor: First we expand dimension and then in each loop concatenate a new row.\n",
    "Resultant tensor after processing will have shape (max_sequence_length+1)*num_sentences*max_sequence_length\n",
    "'''\n",
    "resultant_tensor = tf.expand_dims(input_word_seq_tensor,0)\n",
    "\n",
    "'''We store sequence lengths (useful for seq2seq) for each sequence in final_sequence-> if input was of shape num_sentences, after processing it will be of shape (max_seq_length+1)*num_sentences'''\n",
    "'''Basically if it were [2,2,3] then it would be [[2,2,3],[1,1,2],[1,1,2],[1,1,2]'''\n",
    "tensor_seq_lengths = tf.expand_dims(seq_lengths, 0)\n",
    "seq_lengths_for_dropped = tf.expand_dims(seq_lengths-tf.ones(shape=seq_lengths.shape[0]))\n",
    "\n",
    "\n",
    "for drop_index in range(max_seq_length):\n",
    "    '''Create mask function-> note the drop index changes at each iteration'''\n",
    "    f = lambda word_seq: tf.boolean_mask(word_seq, tf_mask_matrix[:,drop_index])#,padding,\"CONSTANT\") \n",
    "    '''Apply masking and padding'''\n",
    "    temp = tf.pad(tf.map_fn(f, input_word_seq_tensor), padding, \"CONSTANT\") #We apply mask and then pad result to enable concatenation with original \n",
    "    resultant_tensor = tf.concat(resultant_tensor,temp,0)\n",
    "    tensor_seq_lengths = tf.concat(tensor_seq_lengths, seq_lengths_for_dropped,0)\n",
    "\n",
    "\n",
    "\n",
    "#convert returned tensor into the form (n*num_sen, max_len)\n",
    "#give to seq2seq with seq_lens as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'ExpandDims_2:0' shape=(1, 2, 6) dtype=int64>,\n",
       " <tf.Tensor 'Const_25:0' shape=(2, 6) dtype=int64>)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultant_tensor = tf.expand_dims(input_word_seq_tensor,0)\n",
    "resultant_tensor, input_word_seq_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#below we first mask so N*max_sequence_length -> N*max_sequence_length-1\n",
    "#then we pad a single value of 0 to each column to make result of same shape as max_seq_length \n",
    "#Padding makes it again into N*max_sequence_length\n",
    "\n",
    "f = lambda word_seq: tf.boolean_mask(word_seq, tf_mask_matrix[:,0])#,padding,\"CONSTANT\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Pad_1:0' shape=(2, ?) dtype=int64>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input tensor is of shape n\n",
    "tensor = tf.convert_to_tensor(np.array([[0,1,2,3,1,2],[1,2,3,4,3,2]]))\n",
    "\n",
    "tf.pad(tf.map_fn(f, tensor), padding, \"CONSTANT\") #We apply mask and then pad result to enable concatenation with original \n",
    "\n",
    "\n",
    "tf.concatenat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shapes (2,) and (4,) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-a08b2806701b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboolean_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.pyc\u001b[0m in \u001b[0;36mboolean_mask\u001b[0;34m(tensor, mask, name)\u001b[0m\n\u001b[1;32m   1155\u001b[0m           \u001b[0;34m\"Number of mask dimensions must be specified, even if some dimensions\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m           \" are None.  E.g. shape=[None] is ok, but shape=None is not.\")\n\u001b[0;32m-> 1157\u001b[0;31m     \u001b[0mshape_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mndims_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m     \u001b[0mleading_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mndims_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.pyc\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    751\u001b[0m     \"\"\"\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shapes %s and %s are incompatible\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmost_specific_compatible_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (2,) and (4,) are incompatible"
     ]
    }
   ],
   "source": [
    "tensor = tf.convert_to_tensor(np.array([[0,1,2,3,1,2],[1,2,3,4,3,2]]))\n",
    "#mask = np.array([True, False, True, False])\n",
    "#tf.boolean_mask(tensor, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice_7:0' shape=(6,) dtype=bool>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_mask_matrix[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#convert input of batch_size*seq_length into 1*batch_size*seq_length\n",
    "input_seq_tensor = tf.expand_dims(input_seq_tensor,0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in range(seq_length):\n",
    "    tf.boolean_mask(input_seq_tensor, tf_mask_matrix[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 0, 0, 0],\n",
       "       [1, 2, 3, 0, 0, 0],\n",
       "       [1, 2, 3, 0, 0, 0],\n",
       "       [1, 2, 3, 0, 0, 0],\n",
       "       [1, 2, 3, 0, 0, 0],\n",
       "       [1, 2, 3, 0, 0, 0]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply the np mask matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tensor = x3\n",
    "mask = np_mask_matrix\n",
    "z = tf.boolean_mask(tensor, np_mask_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 0, 0, 0, 1, 3, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 3, 0, 0, 1, 2,\n",
       "       3, 0, 0, 1, 2, 3, 0, 0])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "z.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'boolean_mask_11/Gather:0' shape=(?,) dtype=float32>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable(tf.truncated_normal(shape=(seq_length,seq_length,)))\n",
    "tf_mask_matrix = tf.convert_to_tensor(np_mask_matrix, dtype=\"bool\")\n",
    "\n",
    "l = tf.boolean_mask(x,tf_mask_matrix)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x1 = np.array([[1,2,3,0,0,0],[3,4,5,6,0,0]])\n",
    "#First output of [[[2,3,0,0,0],[4,5,6,0,0]] 1,3,0,0,0 1,2,0,0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 2, 3, 0, 0, 0],\n",
       "        [1, 2, 3, 0, 0, 0],\n",
       "        [1, 2, 3, 0, 0, 0],\n",
       "        [1, 2, 3, 0, 0, 0],\n",
       "        [1, 2, 3, 0, 0, 0],\n",
       "        [1, 2, 3, 0, 0, 0]],\n",
       "\n",
       "       [[3, 4, 5, 6, 0, 0],\n",
       "        [3, 4, 5, 6, 0, 0],\n",
       "        [3, 4, 5, 6, 0, 0],\n",
       "        [3, 4, 5, 6, 0, 0],\n",
       "        [3, 4, 5, 6, 0, 0],\n",
       "        [3, 4, 5, 6, 0, 0]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = np.repeat(x1, [6,6], axis =0).reshape(-1,6,6)\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False,  True,  True,  True,  True,  True],\n",
       "       [ True, False,  True,  True,  True,  True],\n",
       "       [ True,  True, False,  True,  True,  True],\n",
       "       [ True,  True,  True, False,  True,  True],\n",
       "       [ True,  True,  True,  True, False,  True],\n",
       "       [ True,  True,  True,  True,  True, False]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_mask_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x1 = x1.reshape(1,2,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3],\n",
       "       [2, 4],\n",
       "       [3, 5]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[0,:,[0,1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mask_matrix = [[1,1,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "seq_length = 6\n",
    "np_mask_matrix = np.ones((seq_length,seq_length)) #num drops=n\n",
    "a = np.array(range(seq_length))\n",
    "#b = np.zeros((3, 4))\n",
    "np_mask_matrix[np.arange(len(a)), a] = 0\n",
    "np_mask_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np_mask_matrix = np_mask_matrix!=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Now given the input seq as a 3d tensor or 2d tensor, we apply mask in either step or we can form a repeat vector and apply the mask to the resultant matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice:0' shape=(10, 100) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "y.eval().shape\n",
    "y[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "o = tf.ones(shape=(100,))\n",
    "1 1 1 1 1 1 <- Num elements based on seq length\n",
    "0 1 1 1 1 1 \n",
    "1 0 1 1 1 1\n",
    "1 1 0 1 1 1 \n",
    "1 1 1 0 1 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ff065ef58c9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'Tensor' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "\"\"\"Inputs:\n",
    "Seq_len\n",
    "Seq indices\n",
    "\n",
    "Procedure:\n",
    "Word_dropped_matrix = []\n",
    "For i in seq_len:\n",
    "    1) Make mask for each step of len = seq_len\n",
    "    2) Apply mask to input seq row (entire row- each column) through above and map_fn in TF to produce the resultant\n",
    "    3) word_dropped_matrix[i] = Batchwise\n",
    "Resultant shape is seq_len*batch\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
